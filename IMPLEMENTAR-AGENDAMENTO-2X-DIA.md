# ğŸš€ Implementar Agendamento 2x por Dia (06h e 14h)

## âœ… **STATUS: CÃ³digo Pronto!**

Todas as modificaÃ§Ãµes jÃ¡ foram implementadas no cÃ³digo. VocÃª sÃ³ precisa **configurar e ativar**.

---

## ğŸ“‹ **Passos para Ativar**

### **1. Adicionar ConfiguraÃ§Ãµes ao .env**

Adicione estas linhas ao seu arquivo `.env`:

```bash
# ===========================================
# CONFIGURAÃ‡Ã•ES DO AGENDADOR (2x POR DIA)
# ===========================================

# ExecuÃ§Ã£o matinal (06:00)
SCHEDULER_MORNING_HOUR=6
SCHEDULER_MORNING_MINUTE=0

# ExecuÃ§Ã£o vespertina (14:00 - 2h da tarde)
SCHEDULER_AFTERNOON_HOUR=14
SCHEDULER_AFTERNOON_MINUTE=0

# Data de inÃ­cio
SCHEDULER_START_DATE=2025-01-21
```

### **2. Habilitar no supervisord.conf**

No arquivo `backend/scraper/supervisord.conf`, linha ~32, altere:

```ini
# DE:
autostart=false

# PARA:
autostart=true
```

### **3. Reiniciar o Container**

```bash
docker-compose down
docker-compose up --build scraper -d
```

### **4. Verificar Logs**

```bash
docker-compose logs -f scraper
```

**VocÃª deve ver:**
```
â° Scheduler configurado para execuÃ§Ã£o duas vezes por dia:
ğŸŒ… ManhÃ£: 06:00
ğŸŒ‡ Tarde: 14:00
âœ… Scraping duas vezes por dia agendado com sucesso
```

---

## ğŸŒ…ğŸŒ‡ **Como Funciona Agora**

### **06:00 da ManhÃ£:**
- â° APScheduler dispara automaticamente
- ğŸš€ Executa: `python scraping.py run --start-date 2025-01-21 --headless`
- ğŸ“… Data: **Hoje** (nÃ£o mais ontem)
- ğŸ“ Salva em: `backend/scraper/reports/json/`

### **14:00 da Tarde:**
- â° APScheduler dispara automaticamente  
- ğŸš€ Executa: `python scraping.py run --start-date 2025-01-21 --headless`
- ğŸ“… Data: **Hoje** (mesmo dia)
- ğŸ“ Salva em: `backend/scraper/reports/json/`

### **Vantagens:**
- ğŸ”„ **Duas execuÃ§Ãµes por dia** = mais chances de capturar publicaÃ§Ãµes
- ğŸ“… **Data atual** = publicaÃ§Ãµes do mesmo dia
- ğŸ¯ **Mesmo cÃ³digo** do `scraping.py` que jÃ¡ funciona perfeitamente

---

## ğŸ§ª **Testes**

### **Teste 1: Verificar ConfiguraÃ§Ãµes**
```bash
docker-compose exec scraper python -c "
from src.infrastructure.config.settings import get_settings
s = get_settings().scheduler
print(f'ğŸŒ… ManhÃ£: {s.morning_execution_hour:02d}:{s.morning_execution_minute:02d}')
print(f'ğŸŒ‡ Tarde: {s.afternoon_execution_hour:02d}:{s.afternoon_execution_minute:02d}')
"
```

**Output esperado:**
```
ğŸŒ… ManhÃ£: 06:00
ğŸŒ‡ Tarde: 14:00
```

### **Teste 2: Verificar Jobs Agendados**
```bash
docker-compose exec scraper python -c "
from src.infrastructure.scheduler.scheduler_adapter import SchedulerAdapter
scheduler = SchedulerAdapter()
jobs = scheduler.scheduler.get_jobs()
for job in jobs:
    print(f'ğŸ“Š Job: {job.id} - {job.name}')
"
```

**Output esperado:**
```
ğŸ“Š Job: morning_scraping - Scraping Matinal DJE-SP
ğŸ“Š Job: afternoon_scraping - Scraping Vespertino DJE-SP
```

### **Teste 3: ExecuÃ§Ã£o Manual**
```bash
# Testar o mesmo comando que serÃ¡ executado automaticamente
docker-compose exec scraper python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless
```

---

## âš™ï¸ **PersonalizaÃ§Ã£o de HorÃ¡rios**

### **Exemplo 1: 08:00 e 16:00**
```bash
SCHEDULER_MORNING_HOUR=8
SCHEDULER_AFTERNOON_HOUR=16
```

### **Exemplo 2: 07:30 e 15:30**
```bash
SCHEDULER_MORNING_HOUR=7
SCHEDULER_MORNING_MINUTE=30
SCHEDULER_AFTERNOON_HOUR=15
SCHEDULER_AFTERNOON_MINUTE=30
```

### **Exemplo 3: 09:00 e 18:00**
```bash
SCHEDULER_MORNING_HOUR=9
SCHEDULER_AFTERNOON_HOUR=18
```

---

## ğŸ” **Monitoramento**

### **Logs de ExecuÃ§Ã£o:**

**06:00:**
```
ğŸ”„ Iniciando execuÃ§Ã£o do scraping Ã s 06:00
ğŸ“… Executando scraping para data: 2025-01-21
ğŸš€ Iniciando DJE Scraper com Playwright
ğŸ“… PerÃ­odo: 2025-01-21 atÃ© 2025-01-21
âœ… ExecuÃ§Ã£o concluÃ­da: [execution-id]
ğŸ“Š PublicaÃ§Ãµes encontradas: X
ğŸ’¾ PublicaÃ§Ãµes salvas: Y
```

**14:00:**
```
ğŸ”„ Iniciando execuÃ§Ã£o do scraping Ã s 14:00
ğŸ“… Executando scraping para data: 2025-01-21
[... mesmo processo ...]
```

### **Arquivos Gerados:**
```
backend/scraper/reports/json/
â”œâ”€â”€ 0001234-56_2025_8_26_0100.json  # ManhÃ£
â”œâ”€â”€ 0001235-67_2025_8_26_0200.json  # ManhÃ£
â”œâ”€â”€ 0001236-78_2025_8_26_0300.json  # Tarde
â””â”€â”€ 0001237-89_2025_8_26_0400.json  # Tarde
```

---

## ğŸš¨ **SoluÃ§Ã£o de Problemas**

### **Problema: "Jobs nÃ£o aparecem"**
1. Verificar se `autostart=true` no supervisord.conf
2. Verificar se main_app estÃ¡ rodando: `docker-compose exec scraper supervisorctl status`
3. Reiniciar: `docker-compose restart scraper`

### **Problema: "ConfiguraÃ§Ãµes nÃ£o carregam"**
1. Verificar se as variÃ¡veis estÃ£o no .env
2. Verificar sintaxe: `SCHEDULER_MORNING_HOUR=6` (sem espaÃ§os)
3. Rebuild: `docker-compose up --build scraper -d`

### **Problema: "ExecuÃ§Ã£o falha"**
1. Testar scraping.py manualmente:
   ```bash
   docker-compose exec scraper python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless
   ```
2. Verificar logs: `docker-compose logs scraper | grep -A 5 -B 5 "erro\|fail\|Error"`

---

## ğŸ¯ **Resumo Final**

**VocÃª tem agora:**

- âœ… **CÃ³digo implementado** e funcional
- âœ… **Duas execuÃ§Ãµes por dia** (06:00 e 14:00)
- âœ… **Data atual** (nÃ£o mais dia anterior)
- âœ… **Mesmo scraping.py** que jÃ¡ funciona
- âœ… **ConfiguraÃ§Ã£o flexÃ­vel** via .env

**Para ativar:**
1. â• Adicionar configuraÃ§Ãµes ao .env
2. âœï¸ Alterar autostart=true no supervisord.conf  
3. ğŸ”„ Reiniciar container
4. ğŸ‘€ Monitorar logs

**O agendamento 2x por dia estÃ¡ pronto para funcionar!** ğŸš€ 