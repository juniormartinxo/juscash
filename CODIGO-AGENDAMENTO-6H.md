# ğŸ•• CÃ³digo EspecÃ­fico do Agendamento 2x por Dia (06h e 14h)

## ğŸ“ **1. ConfiguraÃ§Ã£o dos HorÃ¡rios (settings.py)**

**Arquivo:** `backend/scraper/src/infrastructure/config/settings.py`
**Linhas:** 81-90

```python
class SchedulerSettings(BaseSettings):
    """ConfiguraÃ§Ãµes do scheduler"""

    # HorÃ¡rios de execuÃ§Ã£o (duas vezes por dia)
    morning_execution_hour: int = Field(default=6, env="SCHEDULER_MORNING_HOUR")     # ğŸŒ… 06:00 - ManhÃ£
    morning_execution_minute: int = Field(default=0, env="SCHEDULER_MORNING_MINUTE") # ğŸŒ… 0 minutos
    afternoon_execution_hour: int = Field(default=14, env="SCHEDULER_AFTERNOON_HOUR")   # ğŸŒ‡ 14:00 - Tarde
    afternoon_execution_minute: int = Field(default=0, env="SCHEDULER_AFTERNOON_MINUTE") # ğŸŒ‡ 0 minutos
    start_date: str = Field(default="2025-01-21", env="SCHEDULER_START_DATE")
```

**ExplicaÃ§Ã£o:** 
- `morning_execution_hour=6` â†’ **06:00 da manhÃ£**
- `afternoon_execution_hour=14` â†’ **14:00 da tarde (2h da tarde)**
- **Duas execuÃ§Ãµes por dia** com o mesmo cÃ³digo do scraping.py

---

## ğŸ“ **2. CriaÃ§Ã£o dos Agendamentos (scheduler_adapter.py)**

**Arquivo:** `backend/scraper/src/infrastructure/scheduler/scheduler_adapter.py`
**Linhas:** 25-70

```python
def schedule_twice_daily_scraping(
    self,
    start_date: str,
    morning_hour: int,      # ğŸŒ… RECEBE: 6 (manhÃ£)
    morning_minute: int,    # ğŸŒ… RECEBE: 0 
    afternoon_hour: int,    # ğŸŒ‡ RECEBE: 14 (tarde)
    afternoon_minute: int,  # ğŸŒ‡ RECEBE: 0
    scraping_function: Callable[[], Awaitable[None]],
) -> None:
    """
    Agenda execuÃ§Ã£o de scraping duas vezes por dia
    """
    logger.info(f"ğŸ“… Agendando scraping duas vezes por dia a partir de {start_date}")
    logger.info(f"ğŸŒ… ManhÃ£: {morning_hour:02d}:{morning_minute:02d}")
    logger.info(f"ğŸŒ‡ Tarde: {afternoon_hour:02d}:{afternoon_minute:02d}")

    # ğŸŒ… AQUI: CronTrigger para execuÃ§Ã£o matinal
    morning_trigger = CronTrigger(
        hour=morning_hour, minute=morning_minute, start_date=start_date
    )

    self.scheduler.add_job(
        func=scraping_function,        # ğŸŒ… FUNÃ‡ÃƒO: _run_daily_scraping
        trigger=morning_trigger,       # ğŸŒ… TRIGGER: ManhÃ£ Ã s 06:00
        id="morning_scraping",
        name="Scraping Matinal DJE-SP",
        replace_existing=True,
        max_instances=1,
        misfire_grace_time=3600,
    )

    # ğŸŒ‡ AQUI: CronTrigger para execuÃ§Ã£o vespertina  
    afternoon_trigger = CronTrigger(
        hour=afternoon_hour, minute=afternoon_minute, start_date=start_date
    )

    self.scheduler.add_job(
        func=scraping_function,        # ğŸŒ‡ FUNÃ‡ÃƒO: _run_daily_scraping
        trigger=afternoon_trigger,     # ğŸŒ‡ TRIGGER: Tarde Ã s 14:00
        id="afternoon_scraping",
        name="Scraping Vespertino DJE-SP",
        replace_existing=True,
        max_instances=1,
        misfire_grace_time=3600,
    )

    logger.info("âœ… Scraping duas vezes por dia agendado com sucesso")
```

**ExplicaÃ§Ã£o:**
- **Dois CronTriggers:** Um para manhÃ£ (06:00) e outro para tarde (14:00)
- **Dois jobs:** `morning_scraping` e `afternoon_scraping`
- **Mesma funÃ§Ã£o:** Ambos chamam `_run_daily_scraping` do main.py
- **Data atual:** Executa no mesmo dia (nÃ£o no dia anterior)

---

## ğŸ“ **3. ConfiguraÃ§Ã£o do Scheduler (main.py)**

**Arquivo:** `backend/scraper/src/main.py`
**Linhas:** 51-66

```python
async def _setup_scheduler(self):
    """Configura o scheduler para execuÃ§Ã£o diÃ¡ria"""
    # ğŸ•• AQUI: Passa as configuraÃ§Ãµes (hour=6, minute=0) para o SchedulerAdapter
    self.scheduler.schedule_daily_scraping(
        start_date=self.settings.scheduler.start_date,
        hour=self.settings.scheduler.daily_execution_hour,      # ğŸ•• = 6
        minute=self.settings.scheduler.daily_execution_minute,  # ğŸ•• = 0
        scraping_function=self._run_daily_scraping              # ğŸ•• FUNÃ‡ÃƒO executada Ã s 6h
    )

    logger.info(
        f"â° Scheduler configurado para execuÃ§Ã£o diÃ¡ria Ã s "
        f"{self.settings.scheduler.daily_execution_hour:02d}:"
        f"{self.settings.scheduler.daily_execution_minute:02d}"
    )
```

**ExplicaÃ§Ã£o:**
- LÃª as configuraÃ§Ãµes (`hour=6, minute=0`)
- Passa para o `SchedulerAdapter`
- Define que `_run_daily_scraping` serÃ¡ executada Ã s 6h

---

## ğŸ“ **4. FunÃ§Ã£o Executada Ã s 6h (main.py)**

**Arquivo:** `backend/scraper/src/main.py`
**Linhas:** 67-76

```python
async def _run_daily_scraping(self):
    """Executa o scraping diÃ¡rio"""  # ğŸ•• ESTA FUNÃ‡ÃƒO RODA Ã€S 6H DA MANHÃƒ
    try:
        logger.info("ğŸ”„ Iniciando execuÃ§Ã£o diÃ¡ria do scraping")
        
        # ğŸ•• AQUI: Chama o orchestrator que executa o scraping.py
        result = await self.orchestrator.execute_daily_scraping()

        logger.info(f"âœ… ExecuÃ§Ã£o diÃ¡ria concluÃ­da: {result.execution_id}")
        logger.info(f"ğŸ“Š PublicaÃ§Ãµes encontradas: {result.publications_found}")
        logger.info(f"ğŸ’¾ PublicaÃ§Ãµes salvas: {result.publications_saved}")

    except Exception as error:
        logger.error(f"âŒ Erro na execuÃ§Ã£o diÃ¡ria: {error}")
```

**ExplicaÃ§Ã£o:**
- **Esta funÃ§Ã£o Ã© chamada automaticamente Ã s 06:00**
- Executa o `ScrapingOrchestrator.execute_daily_scraping()`

---

## ğŸ“ **5. ExecuÃ§Ã£o do scraping.py (scraping_orchestrator.py)**

**Arquivo:** `backend/scraper/src/application/services/scraping_orchestrator.py`
**Linhas:** 85-120 (mÃ©todo `_execute_scraping_py`)

```python
async def _execute_scraping_py(self) -> dict:
    """
    Executa o scraping.py para fazer o scraping real
    """
    try:
        # Data de ontem (padrÃ£o para execuÃ§Ã£o diÃ¡ria)
        yesterday = datetime.now() - timedelta(days=1)
        date_str = yesterday.strftime("%Y-%m-%d")
        
        # Caminho para o scraping.py
        scraper_dir = Path(__file__).parent.parent.parent.parent
        scraping_py_path = scraper_dir / "scraping.py"
        
        logger.info(f"ğŸ“… Executando scraping para data: {date_str}")
        logger.info(f"ğŸ“„ Usando script: {scraping_py_path}")
        
        # ğŸ•• AQUI: Comando executado Ã s 6h da manhÃ£
        cmd = [
            sys.executable,  # python
            str(scraping_py_path),
            "run",
            "--start-date", date_str,
            "--end-date", date_str,
            "--headless"  # Sempre headless no agendamento
        ]
        
        logger.info(f"ğŸ”„ Executando comando: {' '.join(cmd)}")
        
        # ğŸ•• AQUI: Executa o processo scraping.py
        process = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=str(scraper_dir),
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            env={**dict(os.environ), "PYTHONPATH": str(scraper_dir)}
        )
        
        stdout, stderr = await process.communicate()
        # ... resto do cÃ³digo de tratamento
```

**ExplicaÃ§Ã£o:**
- **Esta funÃ§Ã£o executa `python scraping.py run` Ã s 06:00**
- Usa a data de ontem (comportamento correto para execuÃ§Ã£o diÃ¡ria)
- Sempre em modo headless para estabilidade

---

## ğŸ“ **6. AtivaÃ§Ã£o do Agendamento (supervisord.conf)**

**Arquivo:** `backend/scraper/supervisord.conf`
**Linha:** 32

```ini
[program:main_app]
command=python -m src.main
directory=/app
autostart=true                     # ğŸ•• AQUI: Inicia automaticamente = Ativa o agendamento
autorestart=false
startsecs=3                        
startretries=3                     
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=100                       
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"
```

**ExplicaÃ§Ã£o:**
- `autostart=true` â†’ **Inicia automaticamente quando container sobe**
- `command=python -m src.main` â†’ **Executa o main.py que configura o scheduler**

---

## ğŸ”„ **Fluxo Completo Ã s 6h da ManhÃ£**

```
06:00 â†’ APScheduler (CronTrigger) 
      â†’ _run_daily_scraping() 
      â†’ ScrapingOrchestrator.execute_daily_scraping() 
      â†’ _execute_scraping_py() 
      â†’ subprocess: python scraping.py run --start-date YYYY-MM-DD --headless
      â†’ DJEScraperPlaywright (cÃ³digo completo do scraping)
      â†’ Resultados salvos em reports/json/
```

## ğŸ”§ **Para Alterar o HorÃ¡rio**

1. **Via variÃ¡vel de ambiente (.env):**
```bash
SCHEDULER_DAILY_HOUR=8    # Para 8h da manhÃ£
SCHEDULER_DAILY_MINUTE=30 # Para 8:30
```

2. **Via cÃ³digo (settings.py):**
```python
daily_execution_hour: int = Field(default=8, env="SCHEDULER_DAILY_HOUR")
daily_execution_minute: int = Field(default=30, env="SCHEDULER_DAILY_MINUTE")
```

## ğŸ¯ **Resumo**

O agendamento Ã s **06:00 da manhÃ£** acontece atravÃ©s de:

1. **ConfiguraÃ§Ã£o padrÃ£o:** `default=6` em `settings.py`
2. **CronTrigger:** `CronTrigger(hour=6, minute=0)` em `scheduler_adapter.py` 
3. **APScheduler:** Biblioteca que monitora o tempo e dispara Ã s 6h
4. **ExecuÃ§Ã£o:** Chama `python scraping.py run` automaticamente
5. **AtivaÃ§Ã£o:** `autostart=true` no supervisord.conf

**Ã‰ exatamente isso que executa o scraping Ã s 6h da manhÃ£ todos os dias!** ğŸ••

---

## ğŸ“ **LINHA EXATA: Onde estÃ¡ definido "6"**

### **Arquivo:** `backend/scraper/src/infrastructure/config/settings.py`
### **Linha 81:**

```python
daily_execution_hour: int = Field(default=6, env="SCHEDULER_DAILY_HOUR")
#                                       â†‘
#                                    AQUI: 6h da manhÃ£
```

### **Comandos que serÃ£o executados:**

**06:00 (ManhÃ£):**
```bash
python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless
```

**14:00 (Tarde):**
```bash
python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless
```

**Data:** Sempre a data atual (hoje), nÃ£o mais dia anterior.

## ğŸ¯ **Tabela de Linhas CrÃ­ticas:**

| Arquivo | Linha | CÃ³digo | O que faz |
|---------|-------|--------|-----------|
| `settings.py` | 81-84 | `morning_hour=6, afternoon_hour=14` | **Define 06:00 e 14:00** |
| `scheduler_adapter.py` | 25-70 | `schedule_twice_daily_scraping()` | **Cria 2 agendamentos** |
| `main.py` | 51-66 | `schedule_twice_daily_scraping(...)` | **Configura ambos horÃ¡rios** |
| `main.py` | 67 | `async def _run_daily_scraping(self):` | **FunÃ§Ã£o executada 2x/dia** |
| `scraping_orchestrator.py` | 85-95 | `today = datetime.now()` | **Usa data atual** |
| `supervisord.conf` | 32 | `autostart=true` | **Ativa tudo automaticamente** |

## ğŸ“Š **Jobs Agendados:**
- `morning_scraping` - **06:00**
- `afternoon_scraping` - **14:00** 