# üöÄ API do Scraper - Execu√ß√£o via HTTP

## ‚úÖ **Novos Endpoints Adicionados!**

Agora voc√™ pode executar o comando `scraping.py run` via HTTP atrav√©s da API do scraper.

---

## üåê **URL Base da API**

```
http://localhost:5000
```

**Porta:** 5000 (configurada no docker-compose)

**Documenta√ß√£o Interativa:** http://localhost:5000/docs

---

## üìã **Endpoints Dispon√≠veis**

### **1. Execu√ß√£o Manual com Datas Espec√≠ficas**

**POST** `/run/scraping`

Executa o mesmo comando que voc√™ faria manualmente no terminal.

#### **Payload:**
```json
{
  "start_date": "2025-01-21",
  "end_date": "2025-01-21", 
  "headless": true
}
```

#### **Exemplo cURL:**
```bash
curl -X POST "http://localhost:5000/run/scraping" \
  -H "Content-Type: application/json" \
  -d '{
    "start_date": "2025-01-21",
    "end_date": "2025-01-21",
    "headless": true
  }'
```

#### **Resposta:**
```json
{
  "status": "success",
  "message": "Scraping iniciado para per√≠odo 2025-01-21 at√© 2025-01-21",
  "command": "python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless",
  "parameters": {
    "start_date": "2025-01-21",
    "end_date": "2025-01-21", 
    "headless": true
  },
  "note": "Mesmo comando que voc√™ executaria manualmente via terminal"
}
```

---

### **2. Execu√ß√£o da Data Atual (Conveni√™ncia)**

**POST** `/run/scraping/today?headless=true`

Executa o scraping da data atual automaticamente.

#### **Exemplo cURL:**
```bash
# Modo headless (padr√£o)
curl -X POST "http://localhost:5000/run/scraping/today"

# Com interface gr√°fica
curl -X POST "http://localhost:5000/run/scraping/today?headless=false"
```

#### **Resposta:**
```json
{
  "status": "success",
  "message": "Scraping da data atual (2025-01-21) iniciado",
  "command": "python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless",
  "parameters": {
    "start_date": "2025-01-21",
    "end_date": "2025-01-21",
    "headless": true
  },
  "note": "Execu√ß√£o autom√°tica da data atual"
}
```

---

### **3. Status da API**

**GET** `/status`

Verifica o status dos servi√ßos do scraper.

#### **Exemplo cURL:**
```bash
curl "http://localhost:5000/status"
```

#### **Resposta:**
```json
{
  "status": {
    "monitor": false,
    "scraper": false,
    "multi_date_scraper": false
  },
  "pids": {},
  "script_directory": "/app",
  "python_executable": "/opt/venv/bin/python"
}
```

---

### **4. Informa√ß√µes da API**

**GET** `/`

Retorna informa√ß√µes sobre endpoints dispon√≠veis.

#### **Exemplo cURL:**
```bash
curl "http://localhost:5000/"
```

---

## üß™ **Exemplos de Uso**

### **Exemplo 1: Scraping de Hoje**
```bash
curl -X POST "http://localhost:5000/run/scraping/today"
```

### **Exemplo 2: Scraping de Data Espec√≠fica**
```bash
curl -X POST "http://localhost:5000/run/scraping" \
  -H "Content-Type: application/json" \
  -d '{
    "start_date": "2025-01-20",
    "end_date": "2025-01-20",
    "headless": true
  }'
```

### **Exemplo 3: Scraping de Per√≠odo (M√∫ltiplos Dias)**
```bash
curl -X POST "http://localhost:5000/run/scraping" \
  -H "Content-Type: application/json" \
  -d '{
    "start_date": "2025-01-15",
    "end_date": "2025-01-20",
    "headless": true
  }'
```

### **Exemplo 4: Scraping com Interface Gr√°fica (Debug)**
```bash
curl -X POST "http://localhost:5000/run/scraping" \
  -H "Content-Type: application/json" \
  -d '{
    "start_date": "2025-01-21",
    "end_date": "2025-01-21",
    "headless": false
  }'
```

---

## üêç **Exemplo em Python**

```python
import requests
import json

# URL da API
api_url = "http://localhost:5000"

# Exemplo 1: Scraping de hoje
response = requests.post(f"{api_url}/run/scraping/today")
print("Resposta:", response.json())

# Exemplo 2: Scraping com datas espec√≠ficas
payload = {
    "start_date": "2025-01-21",
    "end_date": "2025-01-21",
    "headless": True
}

response = requests.post(
    f"{api_url}/run/scraping",
    headers={"Content-Type": "application/json"},
    data=json.dumps(payload)
)

print("Resposta:", response.json())

# Exemplo 3: Verificar status
status = requests.get(f"{api_url}/status")
print("Status:", status.json())
```

---

## üì± **Exemplo em JavaScript (Frontend)**

```javascript
// Fun√ß√£o para executar scraping
async function executarScraping(startDate, endDate, headless = true) {
    try {
        const response = await fetch('http://localhost:5000/run/scraping', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                start_date: startDate,
                end_date: endDate,
                headless: headless
            })
        });

        const result = await response.json();
        console.log('Scraping iniciado:', result);
        return result;
    } catch (error) {
        console.error('Erro ao executar scraping:', error);
    }
}

// Uso
executarScraping('2025-01-21', '2025-01-21', true);

// Scraping de hoje
async function scrapingHoje() {
    try {
        const response = await fetch('http://localhost:5000/run/scraping/today', {
            method: 'POST'
        });
        const result = await response.json();
        console.log('Scraping de hoje:', result);
    } catch (error) {
        console.error('Erro:', error);
    }
}
```

---

## üîç **Valida√ß√µes**

### **Formato de Data:**
- **Formato obrigat√≥rio:** `YYYY-MM-DD`
- **Exemplos v√°lidos:** `2025-01-21`, `2024-12-31`
- **Exemplos inv√°lidos:** `21/01/2025`, `2025-1-21`, `21-01-2025`

### **L√≥gica de Datas:**
- **Data final n√£o pode ser anterior √† data inicial**
- **Exemplo inv√°lido:** `start_date: "2025-03-17"`, `end_date: "2025-01-21"`
- **Exemplo v√°lido:** `start_date: "2025-01-21"`, `end_date: "2025-03-17"`
- **Mesma data √© v√°lida:** `start_date: "2025-01-21"`, `end_date: "2025-01-21"`

### **Par√¢metros:**
- `start_date`: **Obrigat√≥rio**, string no formato YYYY-MM-DD
- `end_date`: **Obrigat√≥rio**, string no formato YYYY-MM-DD  
- `headless`: **Opcional**, boolean (default: true)

---

## üö® **Tratamento de Erros**

### **Erro 400 - Formato de Data Inv√°lido:**
```json
{
  "detail": "Formato de start_date inv√°lido. Use YYYY-MM-DD, recebido: 21/01/2025"
}
```

### **Erro 400 - Data Final Anterior √† Data Inicial:**
```json
{
  "detail": "Data final (2025-01-21) n√£o pode ser anterior √† data inicial (2025-03-17)"
}
```

### **Erro 500 - Erro Interno:**
```json
{
  "detail": "scraping.py n√£o encontrado em: /app/scraping.py"
}
```

---

## üìä **Monitoramento**

### **Verificar se API est√° Rodando:**
```bash
curl "http://localhost:5000/"
```

### **Verificar Logs do Container:**
```bash
docker-compose logs -f scraper
```

### **Verificar Processos Ativos:**
```bash
curl "http://localhost:5000/status"
```

---

## üîÑ **Rela√ß√£o com Comando Manual**

| Comando Manual | Endpoint API |
|----------------|--------------|
| `docker-compose exec scraper python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless` | `POST /run/scraping` com `{"start_date": "2025-01-21", "end_date": "2025-01-21", "headless": true}` |
| `docker-compose exec scraper python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --no-headless` | `POST /run/scraping` com `{"start_date": "2025-01-21", "end_date": "2025-01-21", "headless": false}` |

### **Vantagens da API:**
- ‚úÖ **N√£o precisa de acesso ao terminal**
- ‚úÖ **Pode ser chamada de qualquer aplica√ß√£o**
- ‚úÖ **Ideal para integra√ß√£o com frontend**
- ‚úÖ **Execu√ß√£o em background**
- ‚úÖ **Mesmos resultados do comando manual**

---

## üéØ **Casos de Uso**

### **1. Integra√ß√£o com Frontend:**
Adicionar bot√£o "Executar Scraping" na interface web que chama a API.

### **2. Scripts Automatizados:**
Criar scripts Python/JavaScript que executam scraping em hor√°rios espec√≠ficos.

### **3. Webhook/Integra√ß√£o:**
Configurar sistemas externos para disparar scraping via HTTP.

### **4. Monitoramento/Dashboard:**
Criar dashboard que permite executar e monitorar scraping via web.

### **5. Desenvolvimento/Testes:**
Facilitar testes durante desenvolvimento sem precisar acessar terminal.

---

## üöÄ **Resumo**

**Agora voc√™ pode executar o scraping de 3 formas:**

1. ü§ñ **Autom√°tico:** 06:00 e 14:00 (agendamento)
2. üõ†Ô∏è **Manual via terminal:** `docker-compose exec scraper python scraping.py run ...`
3. üåê **Manual via API:** `POST /run/scraping` com JSON

**Todos usam exatamente o mesmo c√≥digo do `scraping.py` e produzem resultados id√™nticos!** üéØ 