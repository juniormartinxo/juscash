# ğŸ•• ConfiguraÃ§Ã£o de Agendamento do Scraper

> Guia consolidado para configuraÃ§Ã£o do agendamento automÃ¡tico do scraper DJE-SP

## âœ… **Status Atual**

O sistema de agendamento estÃ¡ **completamente implementado** e funcional, permitindo execuÃ§Ã£o automÃ¡tica 2x por dia (06:00 e 14:00).

## ğŸ¯ **ConfiguraÃ§Ãµes NecessÃ¡rias**

### **1. VariÃ¡veis de Ambiente (.env)**

Adicione as seguintes linhas ao arquivo `.env`:

```bash
# ===========================================
# CONFIGURAÃ‡Ã•ES DO AGENDADOR (2x POR DIA)
# ===========================================

# ExecuÃ§Ã£o matinal (06:00)
SCHEDULER_MORNING_HOUR=6
SCHEDULER_MORNING_MINUTE=0

# ExecuÃ§Ã£o vespertina (14:00 - 2h da tarde)  
SCHEDULER_AFTERNOON_HOUR=14
SCHEDULER_AFTERNOON_MINUTE=0

# Data de inÃ­cio
SCHEDULER_START_DATE=2025-01-21
```

### **2. Habilitar no supervisord.conf**

No arquivo `backend/scraper/supervisord.conf`, altere:

```ini
# DE:
autostart=false

# PARA:
autostart=true
```

### **3. Ativar o Sistema**

```bash
# Reiniciar container
docker-compose down
docker-compose up --build scraper -d

# Verificar logs
docker-compose logs -f scraper
```

## ğŸŒ…ğŸŒ‡ **Como Funciona**

### **ExecuÃ§Ã£o AutomÃ¡tica:**

- **06:00** - Scraping da data atual
- **14:00** - Scraping da data atual (mesmo dia)
- **Comando executado:** `python scraping.py run --start-date YYYY-MM-DD --headless`

### **Fluxo TÃ©cnico:**

```
APScheduler â†’ CronTrigger â†’ _run_daily_scraping() â†’ ScrapingOrchestrator 
â†’ subprocess: python scraping.py run â†’ DJEScraperPlaywright â†’ Resultados em reports/json/
```

## âš™ï¸ **PersonalizaÃ§Ã£o de HorÃ¡rios**

### **Exemplo 1: 08:00 e 16:00**

```bash
SCHEDULER_MORNING_HOUR=8
SCHEDULER_AFTERNOON_HOUR=16
```

### **Exemplo 2: 07:30 e 15:30**

```bash
SCHEDULER_MORNING_HOUR=7
SCHEDULER_MORNING_MINUTE=30
SCHEDULER_AFTERNOON_HOUR=15
SCHEDULER_AFTERNOON_MINUTE=30
```

## ğŸ§ª **VerificaÃ§Ã£o e Teste**

### **Verificar ConfiguraÃ§Ãµes:**

```bash
docker-compose exec scraper python -c "
from src.infrastructure.config.settings import get_settings
s = get_settings().scheduler
print(f'ğŸŒ… ManhÃ£: {s.morning_execution_hour:02d}:{s.morning_execution_minute:02d}')
print(f'ğŸŒ‡ Tarde: {s.afternoon_execution_hour:02d}:{s.afternoon_execution_minute:02d}')
"
```

### **Verificar Jobs Agendados:**

```bash
docker-compose exec scraper python -c "
from src.infrastructure.scheduler.scheduler_adapter import SchedulerAdapter
scheduler = SchedulerAdapter()
jobs = scheduler.scheduler.get_jobs()
for job in jobs:
    print(f'ğŸ“Š Job: {job.id} - {job.name}')
"
```

### **Teste Manual (mesmo cÃ³digo do agendamento):**

```bash
docker-compose exec scraper python scraping.py run --start-date 2025-01-21 --end-date 2025-01-21 --headless
```

## ğŸ” **Monitoramento**

### **Logs Esperados:**

```
â° Scheduler configurado para execuÃ§Ã£o duas vezes por dia:
ğŸŒ… ManhÃ£: 06:00  
ğŸŒ‡ Tarde: 14:00
âœ… Scraping duas vezes por dia agendado com sucesso
```

**Durante execuÃ§Ã£o:**

```
ğŸ”„ Iniciando execuÃ§Ã£o do scraping Ã s 06:00
ğŸ“… Executando scraping para data: 2025-01-21
ğŸš€ Iniciando DJE Scraper com Playwright
âœ… ExecuÃ§Ã£o concluÃ­da: [execution-id]
ğŸ“Š PublicaÃ§Ãµes encontradas: X
ğŸ’¾ PublicaÃ§Ãµes salvas: Y
```

## ğŸš¨ **Troubleshooting**

### **Jobs nÃ£o aparecem:**

1. Verificar `autostart=true` no supervisord.conf
2. Verificar se main_app estÃ¡ rodando: `docker-compose exec scraper supervisorctl status`
3. Reiniciar: `docker-compose restart scraper`

### **ConfiguraÃ§Ãµes nÃ£o carregam:**

1. Verificar variÃ¡veis no .env
2. Verificar sintaxe (sem espaÃ§os): `SCHEDULER_MORNING_HOUR=6`
3. Rebuild: `docker-compose up --build scraper -d`

### **ExecuÃ§Ã£o falha:**

1. Testar scraping.py manualmente
2. Verificar logs de erro
3. Verificar conectividade

## ğŸ“‹ **IntegraÃ§Ã£o com API HTTP**

O scraper tambÃ©m pode ser executado via API HTTP (porta 5000):

### **ExecuÃ§Ã£o via API:**

```bash
# Scraping de hoje
curl -X POST "http://localhost:5000/run/scraping/today"

# Scraping de datas especÃ­ficas
curl -X POST "http://localhost:5000/run/scraping" \
  -H "Content-Type: application/json" \
  -d '{
    "start_date": "2025-01-21",
    "end_date": "2025-01-21",
    "headless": true
  }'
```

### **Verificar status:**

```bash
curl "http://localhost:5000/status"
```

## âœ… **Resumo**

**VocÃª tem 3 formas de execuÃ§Ã£o:**

1. ğŸ¤– **AutomÃ¡tico:** 06:00 e 14:00 (agendamento)
2. ğŸ› ï¸ **Manual via terminal:** `docker-compose exec scraper python scraping.py run ...`
3. ğŸŒ **Manual via API:** `POST /run/scraping` com JSON

**Todos usam exatamente o mesmo cÃ³digo do `scraping.py` funcional!**

---

**Para mais detalhes tÃ©cnicos, consulte:**

- [DocumentaÃ§Ã£o do Scraper](./README.md)
- [Guia de ImplementaÃ§Ã£o](./IMPLEMENTATION-GUIDE.md)
- [Troubleshooting Geral](../TROUBLESHOOTING.md)
