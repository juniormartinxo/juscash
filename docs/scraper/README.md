# API do Scraper

Esta API permite controlar o scraper e o servi√ßo de monitoramento atrav√©s de endpoints HTTP.

## Instala√ß√£o

1. Instale as depend√™ncias adicionais:

```bash
pip install fastapi uvicorn
```

## Iniciando a API

Execute o seguinte comando na pasta raiz do scraper:

```bash
python start_api.py
```

A API estar√° dispon√≠vel em `http://localhost:8000`.

## Documenta√ß√£o da API

A documenta√ß√£o interativa da API estar√° dispon√≠vel em:

- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## Endpoints

### Executar Comandos

**POST** `/run`

Executa um comando do scraper em background.

Comandos dispon√≠veis:

- `monitor`: Inicia o monitoramento de arquivos JSON
- `scraper`: Executa o scraper b√°sico (scraper_cli.py run)
- `multi_date_scraper`: Executa o scraper para m√∫ltiplas datas
- `scraper_cli`: Executa o scraper via CLI (mesmo que 'scraper')

Exemplo de requisi√ß√£o para iniciar o monitoramento:

```json
{
    "command": "monitor",
    "args": {
        "api_endpoint": "http://localhost:8000"
    }
}
```

Exemplo de requisi√ß√£o para executar o scraper:

```json
{
    "command": "scraper",
    "args": {
        "date": "2025-06-15"
    }
}
```

Exemplo de requisi√ß√£o para executar o multi-date scraper:

```json
{
    "command": "multi_date_scraper",
    "args": {
        "start_date": "2025-06-15",
        "end_date": "2025-06-17"
    }
}
```

### Endpoints Espec√≠ficos

**POST** `/run/multi-date-scraper`

Executa o scraper para m√∫ltiplas datas em background.

```json
{
    "args": {
        "start_date": "2025-06-15",
        "end_date": "2025-06-17"
    }
}
```

**POST** `/run/scraper-cli`

Executa o scraper CLI em background.

```json
{
    "args": {
        "date": "2025-06-15"
    }
}
```

### Verificar Status

**GET** `/status`

Retorna o status dos servi√ßos do scraper.

Exemplo de resposta:

```json
{
    "monitor": true,
    "scraper": false
}
```

### Parar Servi√ßos

**POST** `/stop/{service}`

Para um servi√ßo espec√≠fico. O par√¢metro `service` pode ser:

- `monitor`: Para o servi√ßo de monitoramento
- `scraper`: Para o scraper

## Exemplos de Uso com cURL

1. Iniciar o monitoramento:

    ```bash
    curl -X POST http://localhost:8000/run \
    -H "Content-Type: application/json" \
    -d '{"command": "monitor", "args": {"api_endpoint": "http://localhost:8000"}}'
    ```

2. Executar o scraper:

    ```bash
    curl -X POST http://localhost:8000/run \
    -H "Content-Type: application/json" \
    -d '{"command": "scraper", "args": {"date": "2025-06-15"}}'
    ```

3. Verificar status:

    ```bash
    curl http://localhost:8000/status
    ```

4. Executar o multi-date scraper:

    ```bash
    curl -X POST http://localhost:8000/run/multi-date-scraper \
    -H "Content-Type: application/json" \
    -d '{"args": {"start_date": "2025-06-15", "end_date": "2025-06-17"}}'
    ```

5. Executar o scraper CLI:

    ```bash
    curl -X POST http://localhost:8000/run/scraper-cli \
    -H "Content-Type: application/json" \
    -d '{"args": {"date": "2025-06-15"}}'
    ```

6. Parar o monitoramento:

    ```bash
    curl -X POST http://localhost:8000/stop/monitor
    ```

7. Parar o multi-date scraper:

    ```bash
    curl -X POST http://localhost:8000/stop/multi_date_scraper
    ```

## üß™ Testes

O sistema de scraper possui uma suite completa de testes unit√°rios e de integra√ß√£o.

### Executar Testes

```bash
cd backend/scraper

# Instalar depend√™ncias de teste
pip install -r tests/requirements-test.txt

# Executar todos os testes
python -m pytest tests/ -v

# Testes unit√°rios apenas
python -m pytest tests/unit/ -v

# Testes de integra√ß√£o apenas
python -m pytest tests/integration/ -v

# Verificar setup do sistema
python scripts/verify-scraper-setup.py
```

### Documenta√ß√£o Completa

Para informa√ß√µes detalhadas sobre a estrutura de testes, cobertura e melhorias realizadas, consulte:

üìñ **[Documenta√ß√£o Completa dos Testes](TESTES-AUDITORIA.md)**

---
