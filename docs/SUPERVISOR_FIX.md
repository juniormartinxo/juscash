# Corre√ß√£o de Problemas do Supervisor

Este documento explica como resolver os problemas identificados nos logs do supervisord.

## üêõ Problemas Identificados

### 1. `scraper_api` entrando em estado FATAL
```
WARN exited: scraper_api (exit status 0; not expected)
INFO gave up: scraper_api entered FATAL state, too many start retries too quickly
```

### 2. `multi_date_scraper` reiniciando constantemente
```
WARN exited: multi_date_scraper (exit status 0; not expected)
INFO gave up: multi_date_scraper entered FATAL state, too many start retries too quickly
```

## ‚úÖ Solu√ß√µes Aplicadas

### 1. Configura√ß√£o do `multi_date_scraper`

**Problema**: O scraper estava reiniciando quando terminava normalmente (todas as datas processadas).

**Solu√ß√£o**:
```ini
[program:multi_date_scraper]
autostart=false                     # N√£o inicia automaticamente
autorestart=false                   # N√£o reinicia quando termina normalmente
```

### 2. Corre√ß√£o das Datas

**Problema**: O sistema estava usando 2024/2025 incorretamente.

**Solu√ß√£o**: Ajustadas para o ano correto do sistema (2025):
```python
START_DATE = "17/03/2025"  # Mar√ßo de 2025
END_DATE = "NOW"           # Junho de 2025
```

## üöÄ Como Usar Agora

### Inicializa√ß√£o Manual do Multi-Date Scraper

```bash
# Entrar no supervisorctl
supervisorctl

# Verificar status
status

# Iniciar o multi-date scraper manualmente
start multi_date_scraper

# Monitorar logs
tail -f multi_date_scraper
```

### Estados Esperados

1. **Primeira execu√ß√£o**: 
   - Inicializa 93 datas (17/03/2025 at√© 17/06/2025)
   - Processa as datas com 3 workers
   - Termina com exit status 0

2. **Execu√ß√µes subsequentes**:
   - Se todas as datas foram processadas: termina imediatamente
   - Se h√° datas pendentes: continua o processamento

### Monitoramento

```bash
# Monitor cont√≠nuo de progresso
start progress_monitor

# Ver status do monitor
status progress_monitor

# Ver logs do monitor
tail -f progress_monitor
```

## üîß Troubleshooting

### Se o `scraper_api` continua falhando

1. **Verificar logs espec√≠ficos**:
```bash
supervisorctl tail scraper_api stderr
```

2. **Desabilitar temporariamente**:
```bash
supervisorctl stop scraper_api
```

3. **O `multi_date_scraper` funciona independentemente da API**

### Se n√£o h√° trabalho para processar

```bash
# Verificar arquivo de progresso
cat src/scrap_workrs.json

# Resetar progresso (CUIDADO!)
rm src/scrap_workrs.json
supervisorctl start multi_date_scraper
```

### Se workers n√£o processam

1. **Verificar datas no arquivo de progresso**
2. **Logs de debug do scraper**
3. **Conex√£o com DJE-SP**

## üìã Checklist de Verifica√ß√£o

- [ ] Data do sistema est√° correta (2025)
- [ ] Arquivo `src/scrap_workrs.json` existe e √© v√°lido
- [ ] H√° datas n√£o processadas no arquivo
- [ ] `multi_date_scraper` n√£o est√° em loop infinito
- [ ] Workers t√™m recursos suficientes (mem√≥ria, browser)

## üéõÔ∏è Controles R√°pidos

```bash
# Status completo
supervisorctl status

# Logs em tempo real
supervisorctl tail -f multi_date_scraper

# Parar tudo
supervisorctl stop all

# Iniciar essenciais
supervisorctl start file_monitor multi_date_scraper progress_monitor
```

## üí° Dicas de Performance

1. **Reduzir workers se necess√°rio**:
   ```python
   NUM_WORKERS = 2  # Em vez de 3
   ```

2. **Monitorar recursos do sistema**:
   ```bash
   htop  # CPU e mem√≥ria
   ```

3. **Verificar conectividade**:
   ```bash
   curl -I https://esaj.tjsp.jus.br/cdje/
   ```

---

**O sistema est√° agora configurado para funcionamento est√°vel e controlado manualmente.** 