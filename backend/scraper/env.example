# =============================================================================
# CONFIGURAÇÃO DO SCRAPER DJE - JUSCASH
# =============================================================================
# Este arquivo contém as configurações necessárias para o funcionamento do
# scraper do Diário da Justiça Eletrônico (DJE).
# 
# INSTRUÇÕES:
# 1. Copie este arquivo para .env na raiz do projeto
# 2. Configure as variáveis com seus valores específicos
# 3. Mantenha este arquivo seguro e não o commite no Git
# =============================================================================

# -----------------------------------------------------------------------------
# BANCO DE DADOS (OBRIGATÓRIO)
# -----------------------------------------------------------------------------
# URL de conexão com PostgreSQL
# Formato: postgresql://usuario:senha@host:porta/nome_do_banco
POSTGRES_URL_ASYNC=postgresql+asyncpg://juscash_user:juscash_password@localhost:5432/juscash_db

# -----------------------------------------------------------------------------
# REDIS (OPCIONAL - para cache e performance)
# -----------------------------------------------------------------------------
# URL de conexão com Redis
# Formato: redis://host:porta/database_number
# Se não configurado, o scraper funcionará sem cache
REDIS_URL=redis://localhost:6379/0

# Senha do Redis (se configurada)
# REDIS_PASSWORD=sua_senha_redis

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DO DJE
# -----------------------------------------------------------------------------
# Parâmetros específicos do Diário da Justiça Eletrônico

# Caderno do DJE (1=Administrativo, 2=Judicial, 3=Eletrônico)
DJE_CADERNO=1

# Instância (1=Primeira Instância, 2=Segunda Instância)
DJE_INSTANCIA=1

# Local/Comarca (código numérico - consulte documentação do DJE)
DJE_LOCAL=1

# Parte (1=Todas as partes, 2=Específica)
DJE_PARTE=1

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE SCRAPING
# -----------------------------------------------------------------------------
# Configurações técnicas do processo de scraping

# Executar browser em modo headless (true/false)
# true = sem interface gráfica (recomendado para produção)
# false = com interface gráfica (útil para debug)
SCRAPING_HEADLESS=true

# Timeout para operações em milissegundos (30000 = 30 segundos)
SCRAPING_TIMEOUT=30000

# User-Agent personalizado (opcional)
# SCRAPING_USER_AGENT="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36"

# Número máximo de tentativas em caso de erro
SCRAPING_MAX_RETRIES=3

# Delay entre requisições em segundos (para evitar sobrecarga)
SCRAPING_DELAY=2

# Termos obrigatórios para filtrar publicações (separados por vírgula)
# Exemplo: "empresa,contrato,licitação"
SCRAPING_REQUIRED_TERMS=termo1,termo2,termo3

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE AGENDAMENTO
# -----------------------------------------------------------------------------
# Configurações para execução automática

# Data de início do agendamento (formato: YYYY-MM-DD)
SCHEDULER_START_DATE=2024-01-01

# Horário de execução diária
SCHEDULER_EXECUTION_HOUR=8
SCHEDULER_EXECUTION_MINUTE=0

# Fuso horário (opcional - padrão: sistema)
# SCHEDULER_TIMEZONE=America/Sao_Paulo

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE LOGGING
# -----------------------------------------------------------------------------
# Configurações do sistema de logs

# Nível de log (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Diretório para salvar logs (relativo ao scraper)
LOG_DIR=logs

# Rotação de logs - tamanho máximo por arquivo em MB
LOG_MAX_SIZE=10

# Número máximo de arquivos de log mantidos
LOG_BACKUP_COUNT=5

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE PERFORMANCE
# -----------------------------------------------------------------------------
# Configurações para otimização de performance

# Número máximo de conexões simultâneas
MAX_CONCURRENT_REQUESTS=5

# Pool de conexões do banco de dados
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# Timeout de conexão com banco em segundos
DB_CONNECT_TIMEOUT=30

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE DESENVOLVIMENTO
# -----------------------------------------------------------------------------
# Configurações específicas para ambiente de desenvolvimento

# Modo de desenvolvimento (true/false)
# Em modo dev, logs são mais verbosos e algumas validações são relaxadas
DEV_MODE=false

# Salvar screenshots em caso de erro (útil para debug)
SAVE_SCREENSHOTS_ON_ERROR=false

# Diretório para screenshots (se habilitado)
SCREENSHOTS_DIR=logs/screenshots

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE NOTIFICAÇÃO (OPCIONAL)
# -----------------------------------------------------------------------------
# Configurações para notificações de status

# Email para notificações (opcional)
# NOTIFICATION_EMAIL=admin@empresa.com

# Webhook para notificações (opcional)
# NOTIFICATION_WEBHOOK=https://hooks.slack.com/services/...

# Notificar apenas em caso de erro (true/false)
# NOTIFY_ONLY_ON_ERROR=true

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES DE PROXY (OPCIONAL)
# -----------------------------------------------------------------------------
# Configurações de proxy se necessário

# URL do proxy HTTP
# HTTP_PROXY=http://proxy.empresa.com:8080

# URL do proxy HTTPS
# HTTPS_PROXY=https://proxy.empresa.com:8080

# Hosts que não devem usar proxy (separados por vírgula)
# NO_PROXY=localhost,127.0.0.1,.local

# -----------------------------------------------------------------------------
# CONFIGURAÇÕES AVANÇADAS
# -----------------------------------------------------------------------------
# Configurações avançadas - altere apenas se necessário

# Timeout para inicialização do Playwright
PLAYWRIGHT_INIT_TIMEOUT=60000

# Número de tentativas para inicializar o browser
BROWSER_INIT_RETRIES=3

# Limpar cache do browser a cada execução
CLEAR_BROWSER_CACHE=true

# Desabilitar imagens para melhor performance
DISABLE_IMAGES=true

# Desabilitar JavaScript (cuidado - pode quebrar alguns sites)
DISABLE_JAVASCRIPT=false

# =============================================================================
# EXEMPLO DE CONFIGURAÇÃO MÍNIMA
# =============================================================================
# Para uma configuração básica, você precisa apenas de:
#
# DATABASE_URL=postgresql://usuario:senha@localhost:5432/banco
# SCRAPING_REQUIRED_TERMS=termo1,termo2
#
# Todas as outras configurações têm valores padrão funcionais.
# ============================================================================= 