#!/usr/bin/env python3
"""
Teste especÃ­fico para captura de links dinÃ¢micos dos PDFs
Demonstra como os parÃ¢metros sÃ£o extraÃ­dos dinamicamente do HTML
"""

import sys
import asyncio
from pathlib import Path

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from infrastructure.web.dje_scraper_adapter import DJEScraperAdapter
from infrastructure.logging.logger import setup_logger

logger = setup_logger(__name__)


async def test_dynamic_link_extraction():
    """
    Testa a extraÃ§Ã£o dinÃ¢mica de links dos elementos tr.ementaClass
    Baseado no HTML real mostrado na imagem
    """

    print("ğŸ§ª Teste de ExtraÃ§Ã£o DinÃ¢mica de Links PDF")
    print("=" * 60)
    print("ğŸ’¡ Demonstra como os parÃ¢metros sÃ£o capturados dinamicamente")
    print()

    scraper = DJEScraperAdapter()

    try:
        # Inicializar scraper
        print("ğŸŒ Inicializando scraper...")
        await scraper.initialize()

        # Navegar e fazer pesquisa
        print("ğŸ“ Navegando para consulta avanÃ§ada...")
        await scraper._navigate_to_advanced_search()

        print("ğŸ“ Preenchendo formulÃ¡rio...")
        search_terms = ["aposentadoria", "benefÃ­cio", "INSS"]
        await scraper._fill_advanced_search_form(search_terms)

        # Aguardar resultados carregarem
        await asyncio.sleep(2)

        # Buscar elementos tr.ementaClass
        print("ğŸ” Buscando elementos tr.ementaClass...")
        ementa_elements = await scraper.page.query_selector_all("tr.ementaClass")

        if not ementa_elements:
            print("âŒ Nenhum elemento tr.ementaClass encontrado")
            return False

        print(f"âœ… Encontrados {len(ementa_elements)} elementos tr.ementaClass")
        print()

        # Analisar cada elemento detalhadamente
        for i, element in enumerate(ementa_elements):
            print(f"ğŸ“‹ ELEMENTO {i+1}:")
            print("-" * 40)

            # Extrair HTML do elemento para anÃ¡lise
            element_html = await element.inner_html()
            print(f"ğŸ“„ HTML (primeiros 200 chars): {element_html[:200]}...")

            # Buscar todos os elementos com onclick
            onclick_elements = await element.query_selector_all("[onclick]")
            print(f"ğŸ”— Total de elementos com onclick: {len(onclick_elements)}")

            # Analisar cada onclick
            for j, onclick_element in enumerate(onclick_elements):
                onclick_attr = await onclick_element.get_attribute("onclick")
                tag_name = await onclick_element.evaluate("el => el.tagName")

                print(f"   ğŸ·ï¸  Elemento {j+1}: <{tag_name.lower()}>")
                print(f"   ğŸ“ onclick: {onclick_attr}")

                # Verificar se Ã© um link de PDF
                if onclick_attr and "consultaSimples.do" in onclick_attr:
                    print(f"   âœ… LINK DE PDF ENCONTRADO!")

                    # Extrair URL usando nossa funÃ§Ã£o
                    pdf_url = await scraper._extract_pdf_url_from_onclick(onclick_attr)
                    if pdf_url:
                        print(f"   ğŸŒ URL completa: {pdf_url}")

                        # Extrair parÃ¢metros individuais
                        import re

                        params = {}
                        param_matches = re.findall(r"(\w+)=([^&]+)", pdf_url)
                        for param_name, param_value in param_matches:
                            params[param_name] = param_value

                        print(f"   ğŸ“Š ParÃ¢metros extraÃ­dos:")
                        for param, value in params.items():
                            print(f"      â€¢ {param}: {value}")
                    else:
                        print(f"   âŒ Falha na extraÃ§Ã£o da URL")
                else:
                    print(f"   âšª NÃ£o Ã© um link de PDF")

                print()

            print("=" * 40)
            print()

            # Limitar a 3 elementos para nÃ£o sobrecarregar o teste
            if i >= 2:
                break

        return True

    except Exception as error:
        print(f"âŒ Erro durante teste: {error}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        await scraper.cleanup()


async def test_url_extraction_patterns():
    """Testa diferentes padrÃµes de onclick que podem aparecer"""

    print("ğŸ§ª Teste de PadrÃµes de ExtraÃ§Ã£o de URL")
    print("=" * 50)

    scraper = DJEScraperAdapter()

    # Exemplos baseados no HTML real da imagem
    test_patterns = [
        # PadrÃ£o da imagem fornecida
        "return popup('/cdje/consultaSimples.do?cdVolume=19&nuDiario=4092&cdCaderno=12&nuSeqpagina=3710');",
        # VariaÃ§Ãµes possÃ­veis
        "return popup('/cdje/consultaSimples.do?cdVolume=20&nuDiario=4093&cdCaderno=12&nuSeqpagina=3711');",
        "popup('/cdje/consultaSimples.do?cdVolume=21&nuDiario=4094&cdCaderno=12&nuSeqpagina=3712');",
        # Com &amp; (HTML encoded)
        "return popup('/cdje/consultaSimples.do?cdVolume=19&amp;nuDiario=4092&amp;cdCaderno=12&amp;nuSeqpagina=3710');",
        # Outros formatos possÃ­veis
        'return popup("/cdje/consultaSimples.do?cdVolume=22&nuDiario=4095&cdCaderno=12&nuSeqpagina=3713");',
    ]

    print("ğŸ“‹ Testando diferentes padrÃµes de onclick:")
    print()

    for i, pattern in enumerate(test_patterns):
        print(f"ğŸ”— PadrÃ£o {i+1}:")
        print(f"   ğŸ“ Input: {pattern}")

        url = await scraper._extract_pdf_url_from_onclick(pattern)
        if url:
            print(f"   âœ… URL extraÃ­da: {url}")

            # Verificar parÃ¢metros
            import re

            params = re.findall(r"(\w+)=([^&]+)", url)
            print(f"   ğŸ“Š ParÃ¢metros: {dict(params)}")
        else:
            print(f"   âŒ Falha na extraÃ§Ã£o")

        print()


if __name__ == "__main__":
    print("ğŸš€ Teste de Captura DinÃ¢mica de Links PDF")
    print("ğŸ’¡ Demonstra como os parÃ¢metros sÃ£o extraÃ­dos do HTML real")
    print()

    # Teste 1: PadrÃµes de extraÃ§Ã£o
    asyncio.run(test_url_extraction_patterns())

    print("\n" + "=" * 60)

    # Teste 2: ExtraÃ§Ã£o dinÃ¢mica real
    success = asyncio.run(test_dynamic_link_extraction())

    if success:
        print("âœ… TESTE PASSOU - Links dinÃ¢micos capturados corretamente!")
        print("ğŸ’¡ Os parÃ¢metros sÃ£o extraÃ­dos dinamicamente do HTML real")
        print("ğŸ“‹ Cada tr.ementaClass pode ter diferentes parÃ¢metros:")
        print("   â€¢ cdVolume: Volume do diÃ¡rio")
        print("   â€¢ nuDiario: NÃºmero do diÃ¡rio")
        print("   â€¢ cdCaderno: CÃ³digo do caderno")
        print("   â€¢ nuSeqpagina: NÃºmero sequencial da pÃ¡gina")
    else:
        print("âŒ TESTE FALHOU - Problemas na captura dinÃ¢mica")

    sys.exit(0 if success else 1)
