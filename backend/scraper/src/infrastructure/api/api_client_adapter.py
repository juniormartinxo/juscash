"""
Adapter - Cliente para comunica√ß√£o com a API
"""

import httpx
import asyncio
from typing import Dict, Any, Optional
from domain.ports.scraping_repository import ScrapingRepositoryPort
from domain.entities.publication import Publication
from domain.entities.scraping_execution import ScrapingExecution
from infrastructure.logging.logger import setup_logger
from infrastructure.config.settings import get_settings

logger = setup_logger(__name__)


class ApiClientAdapter(ScrapingRepositoryPort):
    """
    Implementa√ß√£o do reposit√≥rio que comunica com a API via HTTP
    """

    def __init__(self):
        self.settings = get_settings()
        self.base_url = self.settings.api.base_url
        self.api_key = self.settings.api.scraper_api_key
        self.timeout = self.settings.api.timeout
        self._last_request_time = 0
        self._min_request_interval = 1.0  # M√≠nimo de 1 segundo entre requisi√ß√µes

        # Validar configura√ß√µes cr√≠ticas
        if not self.api_key:
            logger.error("‚ùå SCRAPER_API_KEY n√£o configurada!")
            logger.error("   Configure a vari√°vel de ambiente SCRAPER_API_KEY")
        elif len(self.api_key) < 32:
            logger.warning("‚ö†Ô∏è  SCRAPER_API_KEY parece muito curta (< 32 caracteres)")

        logger.debug(f"üîó API Base URL: {self.base_url}")
        logger.debug(f"üîë API Key configurada: {'‚úÖ' if self.api_key else '‚ùå'}")
        logger.debug(f"‚è∞ Timeout: {self.timeout}s")

    async def _wait_for_rate_limit(self, retry_after: int = None):
        """Implementa rate limiting com backoff exponencial"""
        current_time = asyncio.get_event_loop().time()
        time_since_last_request = current_time - self._last_request_time

        # Se tiver retry_after, usa ele, sen√£o usa o intervalo m√≠nimo
        wait_time = max(
            retry_after or self._min_request_interval,
            self._min_request_interval - time_since_last_request,
        )

        if wait_time > 0:
            logger.debug(f"‚è≥ Aguardando {wait_time:.2f}s por rate limiting")
            await asyncio.sleep(wait_time)

        self._last_request_time = asyncio.get_event_loop().time()

    async def save_publication(self, publication: Publication) -> bool:
        """Salva publica√ß√£o via API"""
        logger.debug(f"üì§ Enviando publica√ß√£o: {publication.process_number}")

        max_retries = 3
        retry_count = 0
        base_delay = 1.0

        while retry_count < max_retries:
            try:
                await self._wait_for_rate_limit()

                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    api_data = publication.to_api_dict()

                    # Log detalhado para debug
                    logger.warning(
                        f"üîç JSON completo sendo enviado para {publication.process_number}:"
                    )
                    import json

                    logger.warning(json.dumps(api_data, ensure_ascii=False, indent=2))

                    response = await client.post(
                        f"{self.base_url}/api/scraper/publications",
                        json=api_data,
                        headers={
                            "Content-Type": "application/json; charset=utf-8",
                            "X-API-Key": self.api_key,
                        },
                    )

                    if response.status_code == 201:
                        logger.debug(
                            f"‚úÖ Publica√ß√£o salva: {publication.process_number}"
                        )
                        return True
                    elif response.status_code == 400:
                        try:
                            error_data = response.json()
                            logger.warning(
                                f"‚ö†Ô∏è  Valida√ß√£o falhou para {publication.process_number}:"
                            )
                            logger.warning(f"   üìã Erro da API: {error_data}")

                            # Tentar extrair detalhes espec√≠ficos do erro
                            if isinstance(error_data, dict):
                                if "error" in error_data:
                                    logger.warning(
                                        f"   ‚ùå Mensagem: {error_data['error']}"
                                    )
                                if "details" in error_data:
                                    logger.warning(
                                        f"   üîç Detalhes: {error_data['details']}"
                                    )
                                if "validation" in error_data:
                                    logger.warning(
                                        f"   üìù Valida√ß√£o: {error_data['validation']}"
                                    )
                                if "field" in error_data:
                                    logger.warning(
                                        f"   üè∑Ô∏è  Campo: {error_data['field']}"
                                    )

                        except Exception:
                            logger.warning(
                                f"‚ö†Ô∏è  Valida√ß√£o falhou para {publication.process_number}: {response.text}"
                            )

                        # Log dos dados enviados para debug
                        api_data = publication.to_api_dict()
                        logger.warning(f"üì§ Dados enviados para API:")
                        logger.warning(
                            f"   üî¢ N√∫mero processo: {api_data.get('process_number')}"
                        )
                        logger.warning(
                            f"   üìÖ Data publica√ß√£o: {api_data.get('publicationDate')}"
                        )
                        logger.warning(
                            f"   üìÖ Data disponibiliza√ß√£o: {api_data.get('availabilityDate')}"
                        )
                        logger.warning(f"   üë• Autores: {api_data.get('authors')}")
                        logger.warning(f"   ‚öñÔ∏è  Advogados: {api_data.get('lawyers')}")
                        logger.warning(
                            f"   üí∞ Valores: gross={api_data.get('grossValue')}, net={api_data.get('netValue')}, interest={api_data.get('interestValue')}, fees={api_data.get('attorneyFees')}"
                        )
                        logger.warning(
                            f"   üìù Conte√∫do (primeiros 100 chars): {api_data.get('content', '')[:100]}..."
                        )
                        return False
                    elif response.status_code == 429:
                        try:
                            error_data = response.json()
                            retry_after = int(error_data.get("retryAfter", 60))
                            logger.warning(
                                f"‚ö†Ô∏è  Rate limit atingido para {publication.process_number}:"
                            )
                            logger.warning(f"   ‚è∞ Aguardar: {retry_after}s")
                            logger.warning(
                                f"   üìä Tentativa: {retry_count + 1}/{max_retries}"
                            )
                            logger.warning(f"   üîÑ Resposta completa: {error_data}")
                        except:
                            retry_after = 60
                            logger.warning(
                                f"‚ö†Ô∏è  Rate limit atingido para {publication.process_number} (resposta: {response.text})"
                            )

                        await self._wait_for_rate_limit(retry_after)
                        retry_count += 1
                        continue
                    elif response.status_code == 401:
                        logger.error(
                            f"üîê Erro de autentica√ß√£o para {publication.process_number}:"
                        )
                        logger.error("   ‚ùå API Key inv√°lida ou n√£o configurada")
                        logger.error("   üîß Verifique a vari√°vel SCRAPER_API_KEY")
                        logger.error(
                            f"   üì§ API Key enviada: {'***' + self.api_key[-4:] if self.api_key else 'NENHUMA'}"
                        )
                        return False  # N√£o tentar novamente para erro de auth
                    else:
                        logger.error(
                            f"‚ùå Erro HTTP {response.status_code} para {publication.process_number}: {response.text}"
                        )
                        retry_count += 1
                        await asyncio.sleep(base_delay * (2**retry_count))
                        continue

            except httpx.ConnectError as error:
                logger.error(f"üîå Erro de conex√£o com a API: {error}")
                logger.error(f"üåê Verifique se a API est√° rodando em: {self.base_url}")
                retry_count += 1
                await asyncio.sleep(base_delay * (2**retry_count))
                continue
            except httpx.TimeoutException:
                logger.error(
                    f"‚è∞ Timeout ao salvar publica√ß√£o: {publication.process_number}"
                )
                retry_count += 1
                await asyncio.sleep(base_delay * (2**retry_count))
                continue
            except Exception as error:
                logger.error(f"‚ùå Erro ao salvar publica√ß√£o: {error}")
                logger.error(f"üîß Tipo do erro: {type(error).__name__}")
                retry_count += 1
                await asyncio.sleep(base_delay * (2**retry_count))
                continue

        return False

    async def save_scraping_execution(self, execution: ScrapingExecution) -> bool:
        """Salva informa√ß√µes da execu√ß√£o (logs locais)"""
        # Por enquanto, apenas logs. Pode ser implementado endpoint espec√≠fico na API
        logger.info(f"üìä Execu√ß√£o conclu√≠da: {execution.execution_id}")
        logger.info(
            f"üìà Estat√≠sticas: Found={execution.publications_found}, "
            f"New={execution.publications_new}, "
            f"Duplicated={execution.publications_duplicated}, "
            f"Failed={execution.publications_failed}"
        )
        return True

    async def check_publication_exists(self, process_number: str) -> bool:
        """Verifica se publica√ß√£o j√° existe"""
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(
                    f"{self.base_url}/api/publications",
                    params={"search": process_number, "limit": 1},
                    headers={"X-API-Key": self.api_key},
                )

                if response.status_code == 200:
                    data = response.json()
                    return data.get("data", {}).get("total", 0) > 0

                return False

        except httpx.ConnectError as error:
            logger.warning(f"üîå Erro de conex√£o ao verificar exist√™ncia: {error}")
            logger.warning(f"üåê Verifique se a API est√° rodando em: {self.base_url}")
            return False  # Em caso de erro, assumir que n√£o existe
        except Exception as error:
            logger.warning(f"‚ö†Ô∏è  Erro ao verificar exist√™ncia: {error}")
            logger.warning(f"üîß Tipo do erro: {type(error).__name__}")
            return False  # Em caso de erro, assumir que n√£o existe
