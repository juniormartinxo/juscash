"""
Sistema de configura√ß√£o din√¢mica para o scraper
"""

import json
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List, Callable
from pydantic import BaseModel, Field

from infrastructure.logging.logger import setup_logger

logger = setup_logger(__name__)


class ScrapingConfig(BaseModel):
    """Configura√ß√£o din√¢mica do scraping"""

    # Configura√ß√µes de busca
    search_terms: List[str] = Field(default=["aposentadoria", "benef√≠cio"])
    max_pages: int = Field(default=20, ge=1, le=100)
    max_publications_per_page: int = Field(default=50, ge=1, le=200)

    # Configura√ß√µes de retry
    max_retries: int = Field(default=3, ge=1, le=10)
    retry_delay_seconds: float = Field(default=5.0, ge=1.0, le=60.0)

    # Configura√ß√µes de timeout
    page_timeout_seconds: int = Field(default=30, ge=5, le=120)
    element_timeout_seconds: int = Field(default=10, ge=1, le=60)

    # Configura√ß√µes de qualidade
    min_confidence_score: float = Field(default=0.7, ge=0.0, le=1.0)
    min_content_length: int = Field(default=50, ge=10, le=1000)

    # Configura√ß√µes de rate limiting
    delay_between_pages_seconds: float = Field(default=2.0, ge=0.5, le=10.0)
    delay_between_requests_seconds: float = Field(default=1.0, ge=0.1, le=5.0)

    # Configura√ß√µes de seletores CSS (podem ser atualizados dinamicamente)
    selectors: Dict[str, str] = Field(
        default={
            "publications": ".publicacao, .conteudo, .texto",
            "next_page": 'a:text("Pr√≥xima"), a:text(">"), .pagination .next',
            "caderno_link": 'a[href*="cdCaderno=3"]',
            "search_input": 'input[name="search"], input[type="search"]',
            "date_input": 'input[type="date"], input[name="data"]',
        }
    )

    # Configura√ß√µes de backup
    enable_backup: bool = Field(default=True)
    backup_retention_days: int = Field(default=30, ge=1, le=365)

    # Configura√ß√µes de debugging
    enable_debug: bool = Field(default=False)
    debug_screenshot_on_error: bool = Field(default=True)
    debug_save_html: bool = Field(default=False)


class DynamicConfigManager:
    """
    Gerenciador de configura√ß√£o din√¢mica
    """

    def __init__(self, config_file: str = "./config/scraping_config.json"):
        self.config_file = Path(config_file)
        self.config_file.parent.mkdir(exist_ok=True)

        self._config: Optional[ScrapingConfig] = None
        self._config_watchers: List[Callable[[ScrapingConfig], None]] = []
        self._last_modified: Optional[float] = None

        # Carregar configura√ß√£o inicial
        self._load_config()

    def _load_config(self) -> None:
        """Carrega configura√ß√£o do arquivo"""
        try:
            if self.config_file.exists():
                with open(self.config_file, "r", encoding="utf-8") as f:
                    config_data = json.load(f)

                self._config = ScrapingConfig(**config_data)
                self._last_modified = self.config_file.stat().st_mtime
                logger.info(f"‚öôÔ∏è  Configura√ß√£o carregada: {self.config_file}")
            else:
                # Criar configura√ß√£o padr√£o
                self._config = ScrapingConfig()
                self._save_config()
                logger.info("‚öôÔ∏è  Configura√ß√£o padr√£o criada")

        except Exception as error:
            logger.error(f"‚ùå Erro ao carregar configura√ß√£o: {error}")
            self._config = ScrapingConfig()  # Fallback para configura√ß√£o padr√£o

    def _save_config(self) -> None:
        """Salva configura√ß√£o no arquivo"""
        try:
            config_data = self._config.dict()

            with open(self.config_file, "w", encoding="utf-8") as f:
                json.dump(config_data, f, indent=2, ensure_ascii=False)

            self._last_modified = self.config_file.stat().st_mtime
            logger.debug(f"‚öôÔ∏è  Configura√ß√£o salva: {self.config_file}")

        except Exception as error:
            logger.error(f"‚ùå Erro ao salvar configura√ß√£o: {error}")

    def get_config(self) -> ScrapingConfig:
        """Obt√©m configura√ß√£o atual"""
        return self._config

    def update_config(self, updates: Dict[str, Any]) -> bool:
        """
        Atualiza configura√ß√£o com novos valores

        Args:
            updates: Dicion√°rio com atualiza√ß√µes

        Returns:
            True se atualizada com sucesso
        """
        try:
            # Aplicar atualiza√ß√µes
            current_data = self._config.dict()
            current_data.update(updates)

            # Validar nova configura√ß√£o
            new_config = ScrapingConfig(**current_data)

            # Salvar se v√°lida
            old_config = self._config
            self._config = new_config
            self._save_config()

            # Notificar watchers
            self._notify_watchers(old_config, new_config)

            logger.info(f"‚öôÔ∏è  Configura√ß√£o atualizada: {list(updates.keys())}")
            return True

        except Exception as error:
            logger.error(f"‚ùå Erro ao atualizar configura√ß√£o: {error}")
            return False

    def add_config_watcher(self, callback: Callable[[ScrapingConfig], None]) -> None:
        """Adiciona callback para mudan√ßas de configura√ß√£o"""
        self._config_watchers.append(callback)

    def _notify_watchers(
        self, old_config: ScrapingConfig, new_config: ScrapingConfig
    ) -> None:
        """Notifica watchers sobre mudan√ßas"""
        for callback in self._config_watchers:
            try:
                callback(new_config)
            except Exception as error:
                logger.error(f"‚ùå Erro em watcher de configura√ß√£o: {error}")

    async def watch_config_file(self, check_interval: float = 10.0) -> None:
        """
        Monitora arquivo de configura√ß√£o por mudan√ßas

        Args:
            check_interval: Intervalo de verifica√ß√£o em segundos
        """
        logger.info(f"üëÅÔ∏è  Monitorando configura√ß√£o: {self.config_file}")

        while True:
            try:
                await asyncio.sleep(check_interval)

                if self.config_file.exists():
                    current_modified = self.config_file.stat().st_mtime

                    if current_modified != self._last_modified:
                        logger.info(
                            "üîÑ Arquivo de configura√ß√£o modificado, recarregando..."
                        )
                        old_config = self._config
                        self._load_config()

                        if self._config != old_config:
                            self._notify_watchers(old_config, self._config)

            except Exception as error:
                logger.error(f"‚ùå Erro no monitoramento de configura√ß√£o: {error}")

    def reset_to_defaults(self) -> bool:
        """Reseta configura√ß√£o para padr√µes"""
        try:
            old_config = self._config
            self._config = ScrapingConfig()
            self._save_config()

            self._notify_watchers(old_config, self._config)

            logger.info("‚öôÔ∏è  Configura√ß√£o resetada para padr√µes")
            return True

        except Exception as error:
            logger.error(f"‚ùå Erro ao resetar configura√ß√£o: {error}")
            return False

    def export_config(self, export_path: str) -> bool:
        """Exporta configura√ß√£o atual"""
        try:
            export_data = {
                "export_timestamp": datetime.now().isoformat(),
                "config": self._config.dict(),
                "metadata": {"scraper_version": "1.0.0", "config_version": "1.0"},
            }

            with open(export_path, "w", encoding="utf-8") as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)

            logger.info(f"üì§ Configura√ß√£o exportada: {export_path}")
            return True

        except Exception as error:
            logger.error(f"‚ùå Erro ao exportar configura√ß√£o: {error}")
            return False

    def import_config(self, import_path: str) -> bool:
        """Importa configura√ß√£o de arquivo"""
        try:
            with open(import_path, "r", encoding="utf-8") as f:
                import_data = json.load(f)

            # Validar e aplicar configura√ß√£o importada
            config_data = import_data.get("config", import_data)
            new_config = ScrapingConfig(**config_data)

            old_config = self._config
            self._config = new_config
            self._save_config()

            self._notify_watchers(old_config, new_config)

            logger.info(f"üì• Configura√ß√£o importada: {import_path}")
            return True

        except Exception as error:
            logger.error(f"‚ùå Erro ao importar configura√ß√£o: {error}")
            return False
