"""
Arquivo: src/adapters/secondary/playwright_scraper.py (VERS√ÉO ATUALIZADA)

Implementa√ß√£o do scraping do DJE usando Playwright com arquitetura modular.
Segue princ√≠pios da Arquitetura Hexagonal como adapter secund√°rio.

VERS√ÉO ATUALIZADA: Integra os novos helpers modulares para pesquisa avan√ßada,
parsing de conte√∫do e navega√ß√£o orchestrada.
"""

import os
import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime
from playwright.async_api import async_playwright, Browser, BrowserContext, Page, TimeoutError as PlaywrightTimeoutError

from src.core.entities.publication import Publication
from src.core.ports.scraper_port import ScraperPort
from src.shared.value_objects import ScrapingCriteria, DJEUrl, ProcessNumber, Status
from src.shared.exceptions import (
    BrowserException, NavigationException, ElementNotFoundException,
    TimeoutException, ParsingException, handle_exception
)
from src.shared.logger import get_logger

# === IMPORTS DOS NOVOS M√ìDULOS ===
from .dje_navigation_helper import DJENavigationHelper
from .dje_search_handler import DJEAdvancedSearchHandler
from .dje_content_parser import DJEContentParser

logger = get_logger(__name__)


class PlaywrightScraperAdapter(ScraperPort):
    """
    Implementa√ß√£o do scraping do DJE usando Playwright (VERS√ÉO MODULAR).
    
    ATUALIZA√á√ÉO: Agora utiliza arquitetura modular com helpers especializados:
    - DJENavigationHelper: Orchestra√ß√£o do fluxo completo
    - DJEAdvancedSearchHandler: Pesquisas avan√ßadas especializadas
    - DJEContentParser: Extra√ß√£o e parsing de conte√∫do
    
    Responsabilidades principais:
    - Gerenciamento do ciclo de vida do browser
    - Interface com o dom√≠nio (Port implementation)
    - Delega√ß√£o para helpers especializados
    - Tratamento de erros de infraestrutura
    """
    
    def __init__(self, 
                 headless: bool = False,
                 timeout: int = 30000,
                 user_agent: Optional[str] = None,
                 max_retries: int = 3):
        """
        Inicializa o adaptador Playwright com configura√ß√£o modular.
        
        Args:
            headless: Se o browser deve rodar em modo headless
            timeout: Timeout padr√£o em milissegundos
            user_agent: User agent customizado
            max_retries: N√∫mero m√°ximo de tentativas em caso de erro
        """
        # Configurar ambiente para WSL
        os.environ['DISPLAY'] = '0'
        os.environ['MOZ_ENABLE_WAYLAND'] = '0'
        os.environ['GDK_BACKEND'] = 'x11'
        
        self.headless = False
        self.timeout = timeout
        self.user_agent = user_agent or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        self.max_retries = max_retries
        
        # Atributos de controle do browser
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
        # === NOVOS HELPERS MODULARES ===
        self.dje_helper: Optional[DJENavigationHelper] = None
        self.search_handler: Optional[DJEAdvancedSearchHandler] = None
        self.content_parser: Optional[DJEContentParser] = None
        
        # Configura√ß√µes espec√≠ficas do adapter
        self.adapter_config = {
            'enable_detailed_logging': True,
            'enable_performance_metrics': True,
            'enable_automatic_retry': True,
            'enable_session_cleanup': True
        }
        
        # M√©tricas de performance
        self.performance_metrics = {
            'initialization_time': None,
            'total_scraping_time': None,
            'publications_per_second': 0.0,
            'error_rate': 0.0
        }
    
    async def initialize(self) -> None:
        """
        Inicializa o browser Playwright e helpers modulares.
        
        ATUALIZA√á√ÉO: Agora inicializa todos os helpers especializados
        ap√≥s configurar o browser.
        
        Raises:
            BrowserException: Se erro na inicializa√ß√£o
        """
        start_time = datetime.now()
        
        try:
            logger.info("üöÄ Inicializando Playwright Scraper (Vers√£o Modular)...")
            
            # === CONFIGURA√á√ÉO DO AMBIENTE ===
            await self._configure_wsl_environment()
            
            # === INICIALIZA√á√ÉO DO PLAYWRIGHT ===
            self.playwright = await async_playwright().start()
            
            # === CONFIGURA√á√ÉO DO BROWSER ===
            browser_args = self._get_browser_args()
            
            self.browser = await self.playwright.firefox.launch(
                headless=self.headless,
                args=browser_args,
                slow_mo=100  # Para debug e estabilidade
            )
            
            # === CRIA√á√ÉO DO CONTEXTO ===
            self.context = await self.browser.new_context(
                user_agent=self.user_agent,
                viewport={'width': 1280, 'height': 720},
                java_script_enabled=True,
                ignore_https_errors=True
            )
            
            # === CRIA√á√ÉO DA P√ÅGINA ===
            self.page = await self.context.new_page()
            
            # Configurar timeouts
            self.page.set_default_timeout(self.timeout)
            self.page.set_default_navigation_timeout(self.timeout)
            
            # === INICIALIZA√á√ÉO DOS HELPERS MODULARES ===
            await self._initialize_helpers()
            
            # === TESTE DE FUNCIONAMENTO ===
            if not self.headless:
                await self._test_browser_functionality()
            
            # === M√âTRICAS DE PERFORMANCE ===
            self.performance_metrics['initialization_time'] = (datetime.now() - start_time).total_seconds()
            
            logger.info("‚úÖ Playwright Scraper inicializado com sucesso")
            logger.info(f"‚è±Ô∏è Tempo de inicializa√ß√£o: {self.performance_metrics['initialization_time']:.2f}s")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar Playwright: {str(e)}")
            await self._cleanup_on_error()
            raise BrowserException("initialize", str(e))
    
    async def _configure_wsl_environment(self) -> None:
        """Configura ambiente WSL para display gr√°fico."""
        logger.info("üîß Configurando ambiente WSL...")
        
        # Configurar display
        os.environ['DISPLAY'] = ':0'
        
        # Verificar disponibilidade do display
        display_available = os.system('xdpyinfo >/dev/null 2>&1') == 0
        
        if not display_available:
            logger.warning("‚ö†Ô∏è Display n√£o detectado - configurando automaticamente...")
            try:
                with open('/etc/resolv.conf', 'r') as f:
                    content = f.read()
                
                import re
                match = re.search(r'nameserver\s+(\S+)', content)
                if match:
                    windows_ip = match.group(1)
                    os.environ['DISPLAY'] = f'{windows_ip}:0'
                    logger.info(f"üñ•Ô∏è Display configurado para: {os.environ['DISPLAY']}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao configurar display automaticamente: {e}")
    
    def _get_browser_args(self) -> List[str]:
        """Retorna argumentos otimizados para o browser."""
        args = [
            '--no-sandbox',
            '--disable-dev-shm-usage'
        ]
        
        if not self.headless:
            args.extend([
                '--new-instance',
                '--no-remote',
                '--display=' + os.environ.get('DISPLAY', ':0')
            ])
            
            # For√ßar X11
            os.environ['MOZ_ENABLE_WAYLAND'] = '0'
            os.environ['GDK_BACKEND'] = 'x11'
        
        return args
    
    async def _initialize_helpers(self) -> None:
        """
        Inicializa todos os helpers modulares.
        
        NOVO M√âTODO: Centraliza a inicializa√ß√£o dos components modulares.
        """
        if not self.page:
            raise BrowserException("initialize_helpers", "P√°gina n√£o dispon√≠vel")
        
        logger.info("üîß Inicializando helpers modulares...")
        
        # Helper principal de navega√ß√£o (orchestrador)
        self.dje_helper = DJENavigationHelper(self.page)
        
        # Helper especializado em pesquisa
        self.search_handler = DJEAdvancedSearchHandler(self.page)
        
        # Helper especializado em parsing
        self.content_parser = DJEContentParser(self.page)
        
        # Configurar session de scraping
        self.dje_helper.configure_scraping_session({
            'max_retries': self.max_retries,
            'enable_pagination': True,
            'max_pages_per_session': 5,  # Limitar para performance
            'max_publications_per_page': 30
        })
        
        logger.info("‚úÖ Helpers modulares inicializados")
    
    async def _test_browser_functionality(self) -> None:
        """Testa funcionalidade b√°sica do browser."""
        logger.info("üß™ Testando funcionalidade do browser...")
        
        try:
            await self.page.goto('about:blank')
            await self.page.wait_for_timeout(1000)
            
            title = await self.page.title()
            logger.info(f"‚úÖ Browser funcionando - T√≠tulo: {title}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Teste de funcionalidade falhou: {e}")
    
    async def navigate_to_dje(self, url: DJEUrl) -> bool:
        """
        Navega para a p√°gina principal do DJE.
        
        M√âTODO MANTIDO: Interface compat√≠vel com a vers√£o anterior.
        
        Args:
            url: URL do DJE
            
        Returns:
            bool: True se navega√ß√£o foi bem-sucedida
            
        Raises:
            BrowserException: Se browser n√£o inicializado
            NavigationException: Se erro na navega√ß√£o
            TimeoutException: Se timeout
        """
        if not self.page:
            raise BrowserException("navigate", "Browser n√£o inicializado")
        
        main_url = url.get_main_url()
        logger.info(f"üåê Navegando para DJE: {main_url}")
        
        for attempt in range(self.max_retries):
            try:
                # Navegar para a p√°gina principal
                response = await self.page.goto(main_url, wait_until='networkidle')
                
                if not response or response.status >= 400:
                    raise NavigationException(
                        f"Erro HTTP {response.status if response else 'desconhecido'}",
                        main_url
                    )
                
                # Aguardar carregamento da p√°gina
                await self.page.wait_for_load_state('domcontentloaded')
                
                # Verificar se chegamos na p√°gina correta
                title = await self.page.title()
                if "dje" not in title.lower() and "di√°rio" not in title.lower():
                    logger.warning(f"‚ö†Ô∏è T√≠tulo da p√°gina n√£o esperado: {title}")
                
                logger.info("‚úÖ Navega√ß√£o para DJE realizada com sucesso")
                return True
                
            except PlaywrightTimeoutError:
                logger.warning(f"‚è∞ Timeout na tentativa {attempt + 1}/{self.max_retries}")
                if attempt == self.max_retries - 1:
                    raise TimeoutException("navigate_to_dje", self.timeout // 1000)
                await asyncio.sleep(2)
                
            except Exception as e:
                logger.error(f"‚ùå Erro na navega√ß√£o (tentativa {attempt + 1}): {str(e)}")
                if attempt == self.max_retries - 1:
                    raise NavigationException(f"Falha ap√≥s {self.max_retries} tentativas", main_url)
                await asyncio.sleep(2)
        
        return False
    
    async def navigate_to_caderno(self, criteria: ScrapingCriteria) -> bool:
        """
        M√âTODO ATUALIZADO: Navega para caderno usando pesquisa avan√ßada modular.
        
        Agora delega para o DJENavigationHelper que orquestrea todo o processo
        de pesquisa avan√ßada usando os helpers especializados.
        
        Args:
            criteria: Crit√©rios de scraping
            
        Returns:
            bool: True se navega√ß√£o/pesquisa foi bem-sucedida
            
        Raises:
            BrowserException: Se helpers n√£o inicializados
            NavigationException: Se erro na pesquisa
        """
        if not self.page:
            raise BrowserException("navigate_caderno", "Browser n√£o inicializado")
        
        if not self.dje_helper:
            raise BrowserException("navigate_caderno", "DJE Helper n√£o inicializado")
        
        logger.info(f"üéØ Executando pesquisa avan√ßada para: {criteria.get_caderno_description()}")
        
        try:
            # Aguardar p√°gina carregar completamente
            await self.page.wait_for_load_state('networkidle')
            
            # === VALIDA√á√ÉO DOS CRIT√âRIOS ===
            validation_result = await self.dje_helper.validate_search_criteria(criteria)
            
            if not validation_result['is_valid']:
                logger.error("‚ùå Crit√©rios de pesquisa inv√°lidos")
                for error in validation_result['errors']:
                    logger.error(f"  - {error}")
                raise NavigationException("Crit√©rios de pesquisa inv√°lidos")
            
            if validation_result['warnings']:
                logger.warning("‚ö†Ô∏è Avisos nos crit√©rios de pesquisa:")
                for warning in validation_result['warnings']:
                    logger.warning(f"  - {warning}")
            
            # === EXECU√á√ÉO DA PESQUISA ===
            # Usar helper principal para orquestrar pesquisa avan√ßada
            success = await self.dje_helper.execute_search_only(criteria)
            
            if success:
                logger.info("‚úÖ Pesquisa avan√ßada executada com sucesso")
                
                # Obter resumo dos resultados
                summary = await self.dje_helper.get_search_results_summary()
                total_results = summary.get('result_metadata', {}).get('total_results', 0)
                logger.info(f"üìä Resultados encontrados: {total_results}")
                
                return True
            else:
                logger.error("‚ùå Falha na execu√ß√£o da pesquisa avan√ßada")
                return False
                
        except PlaywrightTimeoutError:
            raise TimeoutException("navigate_to_caderno", self.timeout // 1000)
        except Exception as e:
            logger.error(f"‚ùå Erro ao executar pesquisa avan√ßada: {str(e)}")
            raise NavigationException(f"Erro na pesquisa avan√ßada: {str(e)}")
    
    async def extract_publications(self, 
                                 criteria: ScrapingCriteria, 
                                 max_publications: Optional[int] = None) -> List[Publication]:
        """
        M√âTODO ATUALIZADO: Extrai publica√ß√µes usando helpers modulares.
        
        Agora utiliza o DJENavigationHelper que orquestrea todo o fluxo:
        1. Navega√ß√£o entre p√°ginas
        2. Extra√ß√£o usando DJEContentParser
        3. Valida√ß√£o usando crit√©rios de neg√≥cio
        
        Args:
            criteria: Crit√©rios de scraping e valida√ß√£o
            max_publications: Limite m√°ximo de publica√ß√µes
            
        Returns:
            List[Publication]: Publica√ß√µes extra√≠das e validadas
            
        Raises:
            BrowserException: Se helpers n√£o inicializados
            ParsingException: Se erro na extra√ß√£o
        """
        if not self.page:
            raise BrowserException("extract_publications", "Browser n√£o inicializado")
        
        if not self.dje_helper:
            raise BrowserException("extract_publications", "DJE Helper n√£o inicializado")
        
        start_time = datetime.now()
        
        logger.info(f"üìã Extraindo publica√ß√µes com crit√©rios: {criteria}")
        if max_publications:
            logger.info(f"üìä Limite m√°ximo: {max_publications} publica√ß√µes")
        
        try:
            # === EXECU√á√ÉO DO FLUXO COMPLETO ===
            # O DJENavigationHelper orquestrea todo o processo:
            # - Navega√ß√£o entre p√°ginas de resultados
            # - Extra√ß√£o usando DJEContentParser
            # - Valida√ß√£o dos crit√©rios
            # - Pagina√ß√£o autom√°tica (se habilitada)
            publications = await self.dje_helper.execute_full_scraping_flow(
                criteria,
                max_publications
            )
            
            # === M√âTRICAS DE PERFORMANCE ===
            extraction_time = (datetime.now() - start_time).total_seconds()
            self.performance_metrics['total_scraping_time'] = extraction_time
            
            if publications and extraction_time > 0:
                self.performance_metrics['publications_per_second'] = len(publications) / extraction_time
            
            # === LOG DE RESULTADOS ===
            logger.info(f"üéâ Extra√ß√£o conclu√≠da:")
            logger.info(f"  üìã Publica√ß√µes extra√≠das: {len(publications)}")
            logger.info(f"  ‚è±Ô∏è Tempo de extra√ß√£o: {extraction_time:.2f}s")
            logger.info(f"  üìà Taxa: {self.performance_metrics['publications_per_second']:.2f} pub/s")
            
            # === ESTAT√çSTICAS DA SESS√ÉO ===
            session_stats = self.dje_helper.get_session_statistics()
            logger.info(f"üìä Estat√≠sticas da sess√£o:")
            logger.info(f"  üìÑ P√°ginas processadas: {session_stats['pages_processed']}")
            logger.info(f"  ‚ùå Erros: {session_stats['errors_count']}")
            logger.info(f"  üìà Taxa de sucesso: {session_stats.get('success_rate', 0):.2%}")
            
            return publications
            
        except Exception as e:
            # Calcular taxa de erro
            session_stats = self.dje_helper.get_session_statistics()
            if session_stats['pages_processed'] > 0:
                self.performance_metrics['error_rate'] = session_stats['errors_count'] / session_stats['pages_processed']
            
            logger.error(f"‚ùå Erro durante extra√ß√£o de publica√ß√µes: {str(e)}")
            raise ParsingException("extract_publications", "fluxo_completo", str(e))
    
    async def extract_publication_details(self, publication: Publication) -> Publication:
        """
        M√âTODO MANTIDO: Extrai detalhes de publica√ß√£o espec√≠fica.
        
        Args:
            publication: Publica√ß√£o para extrair detalhes
            
        Returns:
            Publication: Publica√ß√£o com detalhes atualizados
        """
        logger.debug(f"üìù Detalhes da publica√ß√£o {publication.id} j√° extra√≠dos pelo fluxo modular")
        
        # Na implementa√ß√£o modular, os detalhes s√£o extra√≠dos automaticamente
        # pelo DJEContentParser durante o fluxo principal
        return publication
    
    async def close(self) -> None:
        """
        M√âTODO ATUALIZADO: Fecha browser e limpa recursos modulares.
        
        Agora inclui limpeza dos helpers modulares e relat√≥rio final.
        """
        try:
            logger.info("üîÑ Fechando Playwright Scraper...")
            
            # === LIMPEZA DOS HELPERS ===
            if self.dje_helper:
                await self.dje_helper.cleanup_session()
            
            # === RELAT√ìRIO FINAL DE PERFORMANCE ===
            self._log_final_performance_report()
            
            # === FECHAMENTO DO BROWSER ===
            if self.page:
                await self.page.close()
                self.page = None
            
            if self.context:
                await self.context.close()
                self.context = None
            
            if self.browser:
                await self.browser.close()
                self.browser = None
            
            if self.playwright:
                await self.playwright.stop()
                self.playwright = None
            
            # === LIMPEZA DOS HELPERS ===
            self.dje_helper = None
            self.search_handler = None
            self.content_parser = None
            
            logger.info("‚úÖ Playwright Scraper fechado com sucesso")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao fechar Playwright: {str(e)}")
            raise BrowserException("close", str(e))
    
    def _log_final_performance_report(self) -> None:
        """Gera relat√≥rio final de performance."""
        if self.adapter_config['enable_performance_metrics']:
            logger.info("üìä Relat√≥rio Final de Performance:")
            logger.info(f"  üöÄ Tempo de inicializa√ß√£o: {self.performance_metrics['initialization_time']:.2f}s")
            logger.info(f"  ‚è±Ô∏è Tempo total de scraping: {self.performance_metrics['total_scraping_time']:.2f}s")
            logger.info(f"  üìà Publica√ß√µes por segundo: {self.performance_metrics['publications_per_second']:.2f}")
            logger.info(f"  ‚ùå Taxa de erro: {self.performance_metrics['error_rate']:.2%}")
    
    async def _cleanup_on_error(self):
        """Limpa recursos em caso de erro na inicializa√ß√£o."""
        try:
            if self.page:
                await self.page.close()
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
        except:
            pass  # Ignorar erros durante limpeza
    
    # === M√âTODOS DE CONVENI√äNCIA (NOVOS) ===
    
    async def health_check(self) -> Dict[str, Any]:
        """
        NOVO M√âTODO: Executa verifica√ß√£o de sa√∫de completa.
        
        Returns:
            Dict com status de todos os componentes
        """
        if not self.dje_helper:
            return {'status': 'unhealthy', 'error': 'Helpers n√£o inicializados'}
        
        return await self.dje_helper.execute_health_check()
    
    async def get_scraping_statistics(self) -> Dict[str, Any]:
        """
        NOVO M√âTODO: Retorna estat√≠sticas completas de scraping.
        
        Returns:
            Dict com estat√≠sticas detalhadas
        """
        stats = {
            'adapter_performance': self.performance_metrics.copy(),
            'adapter_config': self.adapter_config.copy()
        }
        
        if self.dje_helper:
            stats['session_statistics'] = self.dje_helper.get_session_statistics()
            stats['configuration_summary'] = self.dje_helper.get_configuration_summary()
        
        return stats
    
    async def validate_criteria_before_scraping(self, criteria: ScrapingCriteria) -> Dict[str, Any]:
        """
        NOVO M√âTODO: Valida crit√©rios antes de iniciar scraping.
        
        Args:
            criteria: Crit√©rios a serem validados
            
        Returns:
            Dict com resultado da valida√ß√£o
        """
        if not self.dje_helper:
            return {'is_valid': False, 'error': 'Helper n√£o inicializado'}
        
        return await self.dje_helper.validate_search_criteria(criteria)