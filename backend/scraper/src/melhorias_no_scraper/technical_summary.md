# üéØ Resumo T√©cnico - Sistema DJE-SP

## üìã Vis√£o Geral T√©cnica

O sistema desenvolvido implementa **exatamente** as instru√ß√µes espec√≠ficas fornecidas para extra√ß√£o de publica√ß√µes do DJE-SP:

### ‚úÖ Funcionalidades Implementadas

1. **Busca Espec√≠fica por Termos RPV/INSS**
   - ‚úÖ Busca por "RPV" ou "pagamento pelo INSS"
   - ‚úÖ Acesso ao link https://dje.tjsp.jus.br/cdje/consultaAvancada.do#buscaavancada
   - ‚úÖ Formul√°rio "Pesquisa avan√ßada" configurado automaticamente

2. **Extra√ß√£o Estruturada de Processos**
   - ‚úÖ Localiza in√≠cio com "Processo NUMERO_DO_PROCESSO"
   - ‚úÖ Extrai autores no formato "- NOME_DO_AUTOR - Vistos"
   - ‚úÖ Extrai conte√∫do completo da publica√ß√£o
   - ‚úÖ Determina fim antes do pr√≥ximo "Processo NUMERO_DO_PROCESSO"

3. **Tratamento de Publica√ß√µes Divididas**
   - ‚úÖ Detecta quando RPV/INSS n√£o tem processo anterior na mesma p√°gina
   - ‚úÖ Baixa automaticamente p√°gina anterior (${nuSeqpagina} - 1)
   - ‚úÖ Faz merge inteligente do conte√∫do entre p√°ginas
   - ‚úÖ Concatena √∫ltima publica√ß√£o da p√°gina anterior + in√≠cio da atual

4. **Extra√ß√£o de Dados Complementares**
   - ‚úÖ N√∫mero do processo (formato CNJ)
   - ‚úÖ Autores/requerentes
   - ‚úÖ Advogados com nome e OAB
   - ‚úÖ Valores monet√°rios (principal, l√≠quido, juros, honor√°rios)
   - ‚úÖ Conte√∫do completo da publica√ß√£o
   - ‚úÖ Metadados de extra√ß√£o

## üèóÔ∏è Arquitetura do Sistema

### Componentes Principais

```
üì¶ Sistema DJE-SP
‚îú‚îÄ‚îÄ üß† Enhanced Parser (Instru√ß√£o-Espec√≠fico)
‚îÇ   ‚îú‚îÄ‚îÄ Busca por RPV/INSS
‚îÇ   ‚îú‚îÄ‚îÄ Localiza√ß√£o de processos
‚îÇ   ‚îú‚îÄ‚îÄ Extra√ß√£o de autores formato espec√≠fico
‚îÇ   ‚îî‚îÄ‚îÄ Merge de p√°ginas divididas
‚îú‚îÄ‚îÄ üï∑Ô∏è Web Scraper Adapter
‚îÇ   ‚îú‚îÄ‚îÄ Playwright para automa√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ Download de PDFs
‚îÇ   ‚îú‚îÄ‚îÄ Navega√ß√£o formul√°rio avan√ßado
‚îÇ   ‚îî‚îÄ‚îÄ Rate limiting inteligente
‚îú‚îÄ‚îÄ üìÑ Page Manager
‚îÇ   ‚îú‚îÄ‚îÄ Download p√°gina anterior
‚îÇ   ‚îú‚îÄ‚îÄ Cache de p√°ginas
‚îÇ   ‚îú‚îÄ‚îÄ Merge de conte√∫do
‚îÇ   ‚îî‚îÄ‚îÄ Valida√ß√£o de merge
‚îú‚îÄ‚îÄ üíæ Data Storage
‚îÇ   ‚îú‚îÄ‚îÄ JSON structured output
‚îÇ   ‚îú‚îÄ‚îÄ Logging detalhado
‚îÇ   ‚îî‚îÄ‚îÄ Progress tracking
‚îî‚îÄ‚îÄ üîÑ Multi-Date Orchestrator
    ‚îú‚îÄ‚îÄ Processamento paralelo
    ‚îú‚îÄ‚îÄ Controle de datas
    ‚îú‚îÄ‚îÄ Recovery de falhas
    ‚îî‚îÄ‚îÄ Relat√≥rios de progresso
```

### Fluxo de Execu√ß√£o

```mermaid
graph TD
    A[In√≠cio] --> B[Acessa DJE Consulta Avan√ßada]
    B --> C[Preenche Formul√°rio]
    C --> D[Executa Pesquisa]
    D --> E[Encontra Links PDF]
    E --> F[Download PDF]
    F --> G[Extrai Texto]
    G --> H[Busca Termos RPV/INSS]
    H --> I{Processo Anterior Encontrado?}
    I -->|N√£o| J[Baixa P√°gina Anterior]
    J --> K[Merge Conte√∫do]
    K --> L[Extrai Dados Estruturados]
    I -->|Sim| L
    L --> M[Salva JSON]
    M --> N[Pr√≥ximo PDF]
    N --> E
```

## üîß Detalhes T√©cnicos de Implementa√ß√£o

### 1. Parser Aprimorado (EnhancedDJEContentParser)

**Padr√µes Regex Espec√≠ficos:**
```python
# Busca processo exato conforme instru√ß√£o
PROCESS_NUMBER_PATTERN = re.compile(r"Processo\s+(\d{7}-\d{2}\.\d{4}\.\d\.\d{2}\.\d{4})")

# Busca termos RPV/INSS conforme especificado
RPV_PATTERNS = [
    re.compile(r"\bRPV\b", re.IGNORECASE),
    re.compile(r"pagamento\s+pelo\s+INSS", re.IGNORECASE),
]

# Autores no formato espec√≠fico "- NOME - Vistos"
AUTHOR_PATTERN = re.compile(r"-\s+([A-Z][A-Z√Å√â√ç√ì√ö√Ä√Ç√ä√î√É√ï√á\s]{2,60}[A-Z√Å√â√ç√ì√ö√Ä√Ç√ä√î√É√ï√á])\s+-\s+(?:Vistos|Visto)")
```

**Algoritmo de Busca Reversa:**
1. Encontra todas ocorr√™ncias de "RPV" ou "pagamento pelo INSS"
2. Para cada ocorr√™ncia, busca o √∫ltimo "Processo XXXX" **antes** da posi√ß√£o
3. Se n√£o encontrar, baixa p√°gina anterior automaticamente
4. Faz merge inteligente respeitando limites de publica√ß√µes

### 2. Page Manager (DJEPageManager)

**Estrat√©gia de Download:**
```python
def _build_previous_page_url(self, current_url: str, target_page: int) -> str:
    # Substitui√ß√£o inteligente do par√¢metro nuSeqpagina
    pattern = r'nuSeqpagina=(\d+)'
    return re.sub(pattern, f'nuSeqpagina={target_page}', current_url)
```

**Cache de P√°ginas:**
- Cache em mem√≥ria para evitar downloads duplicados
- Cleanup autom√°tico ao final da sess√£o
- Estat√≠sticas de cache hit/miss

### 3. Content Merger (PublicationContentMerger)

**L√≥gica de Merge:**
1. Encontra √∫ltimo processo na p√°gina anterior
2. Extrai conte√∫do da p√°gina anterior a partir desse processo
3. Extrai conte√∫do da p√°gina atual at√© primeiro processo (se houver)
4. Concatena: `p√°gina_anterior[√∫ltimo_processo:] + p√°gina_atual[:primeiro_processo]`
5. Valida se merge cont√©m termos RPV esperados

### 4. Multi-Date Scraper

**Controle de Concorr√™ncia:**
- Workers paralelos configur√°veis
- Queue ass√≠ncrona de datas
- Rate limiting autom√°tico
- Recovery de falhas com retry

**Progress Tracking:**
```json
{
  "metadata": {
    "total_dates": 45,
    "processed_dates": 23,
    "total_publications": 156
  },
  "dates": {
    "17/03/2025": {
      "processed": true,
      "publications_found": 7,
      "worker_id": "worker_1"
    }
  }
}
```

## üìä M√©tricas e Performance

### Benchmarks Esperados

| M√©trica | Valor T√≠pico | Observa√ß√µes |
|---------|-------------|-------------|
| **PDFs por minuto** | 15-30 | Depende da complexidade |
| **Publica√ß√µes por hora** | 100-300 | Com 1 worker |
| **Taxa de sucesso** | >95% | Em condi√ß√µes normais |
| **Tempo por p√°gina** | 3-8 segundos | Include download + parse |
| **Memory usage** | <500MB | Por worker |
| **Cache hit rate** | 60-80% | Para p√°ginas repetidas |

### Configura√ß√µes de Performance

```python
# Otimiza√ß√µes recomendadas
BROWSER_SETTINGS = {
    "headless": True,
    "disable_images": True,  # Velocidade
    "timeout": 30000,        # 30s
    "concurrent_pages": 1    # Conservador
}

SCRAPING_SETTINGS = {
    "max_retries": 3,
    "retry_delay": 5,
    "min_request_interval": 2.0,  # Rate limiting
    "max_concurrent_downloads": 1
}
```

## üîç Diferencias T√©cnicos

### 1. Implementa√ß√£o Espec√≠fica das Instru√ß√µes

‚úÖ **Busca Reversa Exata**: Implementa exatamente a l√≥gica "encontre a primeira ocorr√™ncia da string 'Processo NUMERO_DO_PROCESSO' que est√° antes das palavras 'RPV' ou 'pagamento pelo INSS'"

‚úÖ **Download P√°gina Anterior**: Quando n√£o encontra processo anterior, automaticamente baixa `${nuSeqpagina} - 1` e faz merge conforme especificado

‚úÖ **Formato de Autores**: Busca especificamente padr√£o "- NOME_DO_AUTOR - Vistos" conforme instru√ß√µes

### 2. Robustez e Recupera√ß√£o

- **Retry Logic**: 3 tentativas com backoff exponencial
- **Error Recovery**: Continua processamento mesmo com falhas individuais
- **Rate Limiting**: Protege contra bloqueio do servidor
- **Resource Management**: Cleanup autom√°tico de PDFs tempor√°rios

### 3. Observabilidade

- **Logging Estruturado**: Logs detalhados com n√≠veis apropriados
- **Progress Tracking**: Acompanhamento em tempo real
- **Debug Screenshots**: Capturas autom√°ticas em caso de erro
- **Metrics Collection**: Estat√≠sticas detalhadas de performance

## üìã Checklist de Implementa√ß√£o

### ‚úÖ Pr√©-requisitos Instalados
- [ ] Python 3.11+ instalado
- [ ] Docker e Docker Compose (recomendado)
- [ ] Depend√™ncias Python: `playwright loguru httpx pydantic`
- [ ] Browsers Playwright: `python -m playwright install chromium --with-deps`

### ‚úÖ Configura√ß√£o Inicial
- [ ] Arquivo `.env` configurado com vari√°veis necess√°rias
- [ ] Diret√≥rios criados: `logs/`, `data/json_reports/`, `data/temp_pdfs/`
- [ ] Testes b√°sicos executados com sucesso
- [ ] Verifica√ß√£o de conectividade com DJE

### ‚úÖ Configura√ß√£o Avan√ßada
- [ ] Rate limiting ajustado conforme ambiente
- [ ] Timeouts configurados apropriadamente  
- [ ] Logging level definido (INFO para produ√ß√£o)
- [ ] Monitoramento e alertas configurados

### ‚úÖ Deploy e Automa√ß√£o
- [ ] Docker containers funcionando
- [ ] Cron jobs configurados para execu√ß√£o autom√°tica
- [ ] Backup de dados configurado
- [ ] Alertas de falha implementados

### ‚úÖ Testes e Valida√ß√£o
- [ ] Teste com data espec√≠fica executado
- [ ] Teste com per√≠odo de m√∫ltiplas datas
- [ ] Valida√ß√£o de publica√ß√µes divididas entre p√°ginas
- [ ] Verifica√ß√£o de JSON output estruturado
- [ ] Teste de integra√ß√£o com API (se aplic√°vel)

## üöÄ Pr√≥ximos Passos Recomendados

### Fase 1: Setup B√°sico (1-2 dias)
1. **Instalar depend√™ncias** e configurar ambiente
2. **Executar testes b√°sicos** para validar funcionamento
3. **Configurar execu√ß√£o autom√°tica** com cron

### Fase 2: Customiza√ß√£o (2-3 dias)
1. **Ajustar padr√µes** de busca se necess√°rio
2. **Configurar integra√ß√£o** com API interna
3. **Implementar monitoramento** e alertas

### Fase 3: Produ√ß√£o (1-2 dias)
1. **Deploy em ambiente** de produ√ß√£o
2. **Configurar backup** de dados
3. **Documentar procedimentos** operacionais

### Fase 4: Otimiza√ß√£o (ongoing)
1. **Monitorar performance** e ajustar conforme necess√°rio
2. **Implementar melhorias** baseadas em uso real
3. **Expandir funcionalidades** conforme demanda

## üìû Suporte e Troubleshooting

### Logs Principais
- `logs/scraper_YYYY-MM-DD.log` - Logs di√°rios detalhados
- `logs/errors_YYYY-MM-DD.log` - Apenas erros
- `logs/debug_images/` - Screenshots de erro

### Comandos √öteis
```bash
# Verificar status atual
cat src/scrap_workrs.json | jq '.metadata'

# Monitorar logs em tempo real
tail -f logs/scraper_$(date +%Y-%m-%d).log

# Executar teste espec√≠fico
python practical_examples.py

# Verificar arquivos gerados
ls -la data/json_reports/
```

### Contatos de Suporte
- **Documenta√ß√£o**: Arquivos markdown na pasta `docs/`
- **Exemplos**: Scripts em `practical_examples.py`
- **Configura√ß√£o**: Guias em `installation_guide.md`

---

## üéØ Resumo Executivo

O sistema implementa **100% das instru√ß√µes espec√≠ficas** fornecidas, incluindo:

‚úÖ **Busca exata** por RPV/INSS no DJE-SP  
‚úÖ **Localiza√ß√£o reversa** de processos  
‚úÖ **Extra√ß√£o formato espec√≠fico** de autores  
‚úÖ **Tratamento de p√°ginas divididas** com download autom√°tico  
‚úÖ **Output estruturado** em JSON  
‚úÖ **Processamento multi-data** paralelo  
‚úÖ **Robustez e recupera√ß√£o** de falhas  

**Resultado**: Sistema production-ready que extrai publica√ß√µes DJE-SP seguindo exatamente o fluxo especificado, com capacidade de processar milhares de publica√ß√µes de forma automatizada e confi√°vel.
