[supervisord]
nodaemon=true                       ; Roda em foreground (essencial para Docker)
user=scraper                        ; Executa como usuário 'scraper'
logfile=/dev/stdout                 ; Logs para stdout
logfile_maxbytes=0                  ; Sem rotação de logs
pidfile=/tmp/supervisord.pid        ; PID file em diretório temporário
silent=false                        ; Mostra logs de debug

[unix_http_server]
file=/tmp/supervisor.sock           ; Socket file
chmod=0700                          ; Permissões do socket
chown=scraper:scraper              ; Dono do socket

[supervisorctl]
serverurl=unix:///tmp/supervisor.sock ; URL do servidor

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[program:unified_scraper]
command=python unified_scraper_service.py --start-date 17/03/2025 --end-date 20/06/2025
directory=/app
autostart=false
autorestart=false
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
environment=PYTHONUNBUFFERED=1

[program:main_app]
command=python -m src.main
directory=/app
autostart=false                     ; Desabilitado para evitar conflito com multi_date_scraper
autorestart=false
startsecs=3                         ; Aguarda 3s antes de considerar "started"
startretries=3                      ; Máximo 3 tentativas de restart
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=100                        ; Prioridade de inicialização
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"

[program:scraper_api]
command=python -m src.infrastructure.web.scraper_api
directory=/app
autostart=true
autorestart=true
startsecs=5                         ; API pode demorar mais para iniciar
startretries=3
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=200                        ; Inicia após o main_app
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"

[program:file_monitor]
command=python monitor_json_files.py --api-endpoint http://juscash-api:8000
directory=/app
autostart=true
autorestart=true
startsecs=2
startretries=3
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=300
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"

[program:multi_date_scraper]
command=python run_multi_date_scraper.py
directory=/app
autostart=false                      ; Inicia automaticamente UMA VEZ
autorestart=false                   ; Não reinicia quando termina (execução única)
startsecs=10                        ; Aguarda mais tempo para inicialização completa
startretries=1                      ; Apenas 1 tentativa (execução única)
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=400
stopwaitsecs=30                     ; Aguarda 30s para shutdown graceful
stopsignal=SIGINT                   ; Usa SIGINT para permitir cleanup
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"

[program:progress_monitor]
command=python monitor_progress.py --interval 60
directory=/app
autostart=false                     ; Iniciar manualmente quando necessário
autorestart=true
startsecs=3
startretries=3
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=450                        ; Inicia após o multi_date_scraper
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"

[program:scraper_cli]
command=python scraper_cli.py run
directory=/app
autostart=false
autorestart=false
startsecs=2
startretries=1
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
priority=500                        ; Inicia por último
environment=PYTHONPATH="/app",PYTHONUNBUFFERED="1"