# Salvamento Autom√°tico de Relat√≥rios TXT

## Vis√£o Geral

Esta funcionalidade permite que o JusCash Scraper salve automaticamente cada relat√≥rio extra√≠do dos PDFs como um arquivo TXT detalhado. Cada publica√ß√£o processada gera um arquivo individual contendo todas as informa√ß√µes extra√≠das em formato leg√≠vel.

## Caracter√≠sticas

### ‚úÖ Funcionalidades Implementadas

- **Salvamento Autom√°tico**: Cada publica√ß√£o extra√≠da √© automaticamente salva como arquivo TXT
- **Organiza√ß√£o por Data**: Relat√≥rios s√£o organizados em subdiret√≥rios por data (YYYY-MM-DD)
- **Conte√∫do Completo**: Inclui todas as informa√ß√µes da publica√ß√£o (processo, autores, advogados, valores, conte√∫do completo)
- **Metadados de Extra√ß√£o**: Informa√ß√µes sobre como e quando o relat√≥rio foi extra√≠do
- **Configura√ß√£o Flex√≠vel**: Permite personalizar comportamento via vari√°veis de ambiente
- **Tratamento de Erros**: Funciona mesmo com dados incompletos
- **Limpeza Autom√°tica**: Remove relat√≥rios antigos automaticamente

### üìÑ Formato dos Relat√≥rios

Cada arquivo TXT cont√©m:

```
RELAT√ìRIO DE PUBLICA√á√ÉO EXTRA√çDA - DJE-SP
================================================================================
Data de Extra√ß√£o: 15/06/2025 19:30:45
Sistema: JusCash Scraper
================================================================================

INFORMA√á√ïES DO PROCESSO
----------------------------------------
N√∫mero do Processo: 0013168-70.2024.8.26.0053
Data de Publica√ß√£o: 13/11/2024
Data de Disponibiliza√ß√£o: 15/06/2025 19:30:01

PARTES DO PROCESSO
----------------------------------------
R√©u: Instituto Nacional do Seguro Social - INSS

AUTORES:
  - Sheila de Oliveira

ADVOGADOS:
  - Eunice Mendonca da Silva Carvalho (OAB: 138649)
  - Patricia Mendon√ßa de Carvalho Ara√∫jo (OAB: 332295)

VALORES MONET√ÅRIOS
----------------------------------------
Valor Bruto: R$ 129.144,23
Valor L√≠quido: R$ 113.611,90
Juros: R$ 0,00
Honor√°rios Advocat√≠cios: R$ 15.532,33

CONTE√öDO COMPLETO DA PUBLICA√á√ÉO
--------------------------------------------------------------------------------
[Conte√∫do completo da decis√£o judicial...]
--------------------------------------------------------------------------------

METADADOS DE EXTRA√á√ÉO
----------------------------------------
Extraction Date: 15/06/2025 19:30:01
Source Url: /tmp/dje_scraper_pdfs/dje_20250615_193001_091766.pdf
Extraction Method: enhanced_rpv_inss_pattern
Match Type: pagamento pelo INSS
Match Position: 2038
Process Spans Pages: False
Text Length: 5117

INFORMA√á√ïES DO SISTEMA
----------------------------------------
Status: NOVA
Fonte de Scraping: DJE-SP
Caderno: 3
Inst√¢ncia: 1
Local: Capital
Parte: 1

================================================================================
Relat√≥rio gerado automaticamente pelo JusCash Scraper
Arquivo: 20250615_193045.txt
================================================================================
```

## Configura√ß√£o

### Vari√°veis de Ambiente

Voc√™ pode personalizar o comportamento atrav√©s das seguintes vari√°veis de ambiente:

```bash
# Diret√≥rio onde salvar os relat√≥rios
REPORT_OUTPUT_DIR=./relatorios_extraidos

# Habilitar/desabilitar salvamento (true/false)
REPORT_ENABLED=true

# Incluir metadados no relat√≥rio (true/false)
REPORT_INCLUDE_METADATA=true

# Incluir valores monet√°rios (true/false)
REPORT_INCLUDE_VALUES=true

# Incluir conte√∫do completo (true/false)
REPORT_INCLUDE_CONTENT=true

# Dias para manter relat√≥rios (limpeza autom√°tica)
REPORT_CLEANUP_DAYS=30

# Habilitar limpeza autom√°tica (true/false)
REPORT_AUTO_CLEANUP=true

# Encoding dos arquivos
REPORT_ENCODING=utf-8

# Organizar por data (true/false)
REPORT_ORGANIZE_BY_DATE=true

# Formato de data para subdiret√≥rios
REPORT_DATE_FORMAT=%Y-%m-%d
```

### Exemplo de Configura√ß√£o no Docker

```yaml
# docker-compose.yml
services:
  scraper:
    environment:
      - REPORT_OUTPUT_DIR=/app/reports
      - REPORT_ENABLED=true
      - REPORT_CLEANUP_DAYS=60
    volumes:
      - ./reports:/app/reports
```

## Estrutura de Diret√≥rios

```
relatorios_extraidos/
‚îú‚îÄ‚îÄ 2025-06-15/
‚îÇ   ‚îú‚îÄ‚îÄ relatorio_0013168-70_2024_8_26_0053_193045_123.txt
‚îÇ   ‚îú‚îÄ‚îÄ relatorio_0029544-34_2024_8_26_0053_193046_456.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ 2025-06-16/
‚îÇ   ‚îú‚îÄ‚îÄ relatorio_0012345-67_2024_8_26_0053_094521_789.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

## Integra√ß√£o no Fluxo do Scraper

### Pontos de Integra√ß√£o

A funcionalidade est√° integrada em **todos os pontos** onde publica√ß√µes s√£o processadas:

1. **DJE Scraper Adapter** (`dje_scraper_adapter.py`)
   - Salvamento imediato ap√≥s extra√ß√£o do PDF
   - Funciona com parser aprimorado e tradicional
   - Inclui fallback para conte√∫do HTML

2. **Publication Worker** (`publication_worker.py`)
   - Salvamento antes de enviar para API
   - Garante que todas as publica√ß√µes sejam salvas
   - Funciona com processamento em fila

### Fluxo de Execu√ß√£o

```mermaid
graph TD
    A[PDF Baixado] --> B[Texto Extra√≠do]
    B --> C[Publica√ß√£o Parseada]
    C --> D[Salvar Relat√≥rio TXT]
    D --> E[Enviar para API]
    E --> F[Processar na Fila]
    F --> G[Salvar Relat√≥rio TXT novamente]
    G --> H[Finalizar]
```

## Monitoramento e Logs

### Logs de Salvamento

```
üìÑ Relat√≥rio TXT salvo: ./relatorios_extraidos/2025-06-15/relatorio_0013168-70_2024_8_26_0053_193045_123.txt
üìÑ Relat√≥rio TXT salvo (worker): ./relatorios_extraidos/2025-06-15/relatorio_0029544-34_2024_8_26_0053_193046_456.txt
‚ö†Ô∏è Falha ao salvar relat√≥rio TXT para 0012345-67.2024.8.26.0053
‚ùå Erro ao salvar relat√≥rio TXT: [detalhes do erro]
```

### Estat√≠sticas

```python
from infrastructure.files.report_txt_saver import ReportTxtSaver

report_saver = ReportTxtSaver()
stats = report_saver.get_daily_stats()

print(f"Total de relat√≥rios hoje: {stats['total_reports']}")
print(f"Diret√≥rio: {stats['directory']}")
print(f"Arquivos recentes: {stats['files']}")
```

## Testes

### Executar Teste Manual

```bash
cd backend/scraper/src
python local/test_report_saver.py
```

### Teste de Integra√ß√£o

```bash
cd backend/scraper/src
python local/test_integration.py
```

## Resolu√ß√£o de Problemas

### Problemas Comuns

**1. Relat√≥rios n√£o sendo salvos**
- Verificar se `REPORT_ENABLED=true`
- Verificar permiss√µes do diret√≥rio
- Verificar logs para erros espec√≠ficos

**2. Diret√≥rio n√£o criado**
- Verificar permiss√µes de escrita
- Verificar se o path est√° correto
- Verificar vari√°vel `REPORT_OUTPUT_DIR`

**3. Arquivos vazios ou com erro**
- Verificar encoding (`REPORT_ENCODING`)
- Verificar se os dados da publica√ß√£o est√£o v√°lidos
- Verificar logs de erro

### Debug

Para debug mais detalhado, ative os logs de debug:

```python
import logging
logging.getLogger('infrastructure.files.report_txt_saver').setLevel(logging.DEBUG)
```

## Benef√≠cios

### ‚úÖ Vantagens

1. **Backup Completo**: Todos os relat√≥rios extra√≠dos ficam salvos em formato leg√≠vel
2. **Auditoria**: Hist√≥rico completo de extra√ß√µes para an√°lise posterior
3. **Recupera√ß√£o**: Dados dispon√≠veis mesmo se API falhar
4. **An√°lise**: F√°cil an√°lise manual dos relat√≥rios extra√≠dos
5. **Conformidade**: Mant√©m registro detalhado das opera√ß√µes

### üìä Impacto na Performance

- **M√≠nimo**: Opera√ß√£o ass√≠ncrona, n√£o bloqueia o fluxo principal
- **Armazenamento**: ~2-5KB por relat√≥rio (dependendo do conte√∫do)
- **Limpeza**: Autom√°tica, remove arquivos antigos

## Roadmap Futuro

### üöÄ Melhorias Planejadas

- [ ] Compress√£o autom√°tica de relat√≥rios antigos
- [ ] Exporta√ß√£o para outros formatos (JSON, CSV)
- [ ] Dashboard web para visualizar relat√≥rios salvos
- [ ] API para consultar relat√≥rios salvos
- [ ] Notifica√ß√µes por email de relat√≥rios importantes

---

**Desenvolvido para JusCash Scraper v1.0**  
**Data: Junho 2025** 